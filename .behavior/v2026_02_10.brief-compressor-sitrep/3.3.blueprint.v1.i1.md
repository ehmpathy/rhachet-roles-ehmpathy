# blueprint: brief.compress with bhrain/sitrep

## overview

add a brain-powered compressor (`bhrain/sitrep`) alongside the extant llmlingua compressor. the shell orchestrator gains `--via` (format: `$press@$brain`), `--from`, and `--into` flags. the ts engine layer splits into two files: one per press family. a shared module extracts `countTokens` for reuse.

---

## filediffs treestruct

```
src/domain.roles/mechanic/skills/brief.compress/
  ├── brief.compress.sh                    [~] update — add --via, --from, --into flags; route to engine by press family
  ├── compress.ts                          [-] delete — renamed below
  ├── compress.via.llmlingua.ts            [+] create — rename from compress.ts; retain all llmlingua logic
  ├── compress.via.bhrain.ts               [+] create — brain-powered compressor via genContextBrain + sitrep template
  ├── compress.shared.ts                   [+] create — extract countTokens for reuse across both engines
  ├── compress.via.bhrain.integration.test.ts    [+] create — integration tests for bhrain engine (crosses api boundary)
  ├── compress.via.llmlingua.integration.test.ts [+] create — integration tests to confirm llmlingua still works after rename (crosses fs boundary)
  └── brief.compress.integration.test.ts         [+] create — integration tests for full skill invocation via shell
```

---

## codepaths treestruct

### shell orchestrator (`brief.compress.sh`)

```
brief.compress.sh
  ├── arg parse
  │   ├── --via $press@$brain              [+] create — parse press and brain from $via value
  │   ├── --from $path|$glob               [+] create — input path or glob pattern
  │   ├── --into $output                   [+] create — explicit output path (single file only)
  │   ├── --mode plan|apply                [○] retain
  │   ├── --rate $ratio                    [○] retain
  │   └── --force                          [○] retain
  │
  ├── --via parse logic
  │   ├── split on "@"                     [+] create — left = press, right = brain
  │   ├── default brain per press          [+] create — bhrain/sitrep defaults to xai/grok/code-fast-1
  │   └── failfast on malformed            [+] create — "@brain" with no press → error
  │
  ├── --into + glob guard                  [+] create — failfast if --into with glob --from
  │
  ├── press family route
  │   ├── llmlingua/*                      [○] retain — invoke compress.via.llmlingua.js
  │   └── bhrain/*                         [+] create — invoke compress.via.bhrain.js
  │
  ├── engine invocation                    [~] update — pass --via instead of --mech
  ├── output write (.min)                  [○] retain
  ├── --into write                         [+] create — write to $output instead of $path.min
  ├── staleness check                      [○] retain
  └── stats display                        [~] update — show full $press@$brain in tree output
```

### llmlingua engine (`compress.via.llmlingua.ts`)

```
compress.via.llmlingua.ts
  ├── countTokens                          [→] eject — move to compress.shared.ts
  ├── createCompressor                     [○] retain
  ├── computeCompression                   [○] retain — still calls createCompressor + countTokens
  ├── postprocess (bert artifacts)         [○] retain
  ├── parseArgs                            [~] update — accept --from and --via
  └── main                                 [○] retain — same json output contract
```

### bhrain engine (`compress.via.bhrain.ts`)

```
compress.via.bhrain.ts
  ├── imports
  │   ├── genContextBrain                  [←] reuse — from rhachet (auto-discovers brain packages)
  │   ├── countTokens                      [←] reuse — from compress.shared.ts
  │   ├── z (zod)                          [←] reuse — for brain.ask schema
  │   ├── withRetry                        [←] reuse — from wrapper-fns
  │   └── withTimeout                      [←] reuse — from wrapper-fns
  │
  ├── sitrep template                      [+] create — embedded prompt constant
  │   ├── role: distill briefs via sitrep methodology
  │   ├── instruct: preserve rule statements, examples, enforcement levels, code blocks
  │   ├── instruct: output valid markdown
  │   └── instruct: no filler, no repetition, decision-critical content only
  │
  ├── compressViaBhrain                    [+] create — core compression procedure
  │   ├── genContextBrain({ choice: { atom: brainSlug } })
  │   ├── read source brief content
  │   ├── count tokens before
  │   ├── brain.atom.ask with sitrep template + source content
  │   │   ├── schema: z.string()
  │   │   ├── withRetry (3 attempts)
  │   │   └── withTimeout (60 seconds)
  │   ├── count tokens after
  │   ├── compute ratio
  │   └── return { compressed, tokensBefore, tokensAfter, ratio }
  │
  ├── parseArgs                            [+] create — --from, --via, --json
  └── main                                 [+] create — same json output contract as llmlingua
```

### shared module (`compress.shared.ts`)

```
compress.shared.ts
  ├── countTokens                          [→] eject from compress.ts
  │   ├── import js-tiktoken
  │   ├── use cl100k_base encoder
  │   └── return token count
  └── (export only)
```

---

## contracts

### 1. shell → ts engine json contract

both engines must emit identical json to stdout:

```json
{
  "compressed": "<markdown string>",
  "tokensBefore": 3012,
  "tokensAfter": 412,
  "ratio": 7.31
}
```

the shell reads this via `jq` and handles display + file write uniformly.

### 2. `--via` parse contract

```
input: --via $value
output: { press: string, brain: string }

rules:
  1. if $value contains "@" → split: left = press, right = brain
  2. if $value has no "@" and contains "/" → treat as press, apply default brain
     - bhrain/sitrep → brain defaults to xai/grok/code-fast-1
  3. if $value starts with "@" → failfast: "expected format $press@$brain"
  4. if $value has no "@" and no "/" → failfast: "expected format $press@$brain"
```

### 3. brain.atom.ask contract

```ts
const contextBrain = await genContextBrain({ choice: { atom: brainSlug } });

contextBrain.brain.atom.ask<string>({
  brain: { slug: brainSlug },
  role: { briefs: [] },
  prompt: `${SITREP_TEMPLATE}\n\n---\n\nsource brief:\n\n${sourceContent}`,
  schema: {
    output: z.string(),
  },
})
```

### 4. sitrep template contract

the template must instruct the brain to:
- read the full brief and grasp its objective
- distill into decision-critical content only
- preserve: rule statements, positive examples (at least one), enforcement levels, code blocks
- output: valid markdown
- forbid: filler, repetition, nice-to-haves

### 5. api key resolution contract

handled by `genContextBrain` — it auto-discovers installed brain packages and throws `BrainChoiceNotFoundError` if the slug is unrecognized or the required api key is absent. the ts engine catches this error and failfasts with the error message.

---

## composition

```
human
  └─ npx rhachet run --skill brief.compress --from $path --via $press@$brain
       └─ brief.compress.sh
            ├─ parse --via → { press, brain }
            ├─ route by press family:
            │   ├─ llmlingua/* → node compress.via.llmlingua.js --from $path --via $brain --json
            │   └─ bhrain/*   → node compress.via.bhrain.js --from $path --via $brain --json
            ├─ read json result from stdout
            ├─ display tree output (tokens.before, tokens.after, ratio.actual)
            └─ if mode=apply: write .min file (or --into path)
```

---

## test coverage

### integration tests (`compress.via.bhrain.integration.test.ts`)

crosses api boundary (brain.ask → llm api)

| test | what it covers |
|------|----------------|
| sitrep template includes preserve-code-blocks instruction | template contract |
| sitrep template includes preserve-rule-statement instruction | template contract |
| genContextBrain resolves xai brain slug | brain resolution |
| genContextBrain resolves anthropic brain slug | brain resolution |
| compressViaBhrain returns valid result shape | output contract |
| compressViaBhrain compressed output preserves code blocks | sitrep fidelity |

### integration tests (`compress.via.llmlingua.integration.test.ts`)

crosses fs boundary (bert model load from disk)

| test | what it covers |
|------|----------------|
| computeCompression still works after rename | rename safety |
| countTokens import from shared module works | eject safety |

### integration tests (`brief.compress.integration.test.ts`)

full skill invocation via shell (spawnSync)

| test | what it covers | criteria ref |
|------|----------------|--------------|
| --via bhrain/sitrep plan mode shows preview without .min write | usecase.7 | plan mode |
| --via bhrain/sitrep apply mode writes .min file | usecase.1 | apply mode |
| --via bhrain/sitrep --into $output writes to $output | usecase.1 | --into flag |
| --via bhrain/sitrep preserves rule statement in output | usecase.4 | sitrep fidelity |
| --via bhrain/sitrep preserves code blocks in output | usecase.4 | code preservation |
| --via bhrain/sitrep@xai/grok/code-fast-1 parses correctly | usecase.3 | press@brain parse |
| --via bhrain/sitrep (no @brain) defaults to grok code-fast-1 | usecase.3 | default brain |
| --via tinybert (bare, no @ or /) failfasts | usecase.3 | malformed parse |
| --via @xai/grok/code-fast-1 (no press) failfasts | usecase.3 | malformed parse |
| --into with glob --from failfasts | usecase.5 | error path |
| no api key failfasts with clear message | usecase.5 | error path |
| empty brief emits empty .min | usecase.5 | empty input |
| --from no-match failfasts | usecase.5 | error path |
| --via llmlingua/v2@tinybert works | usecase.6 | llmlingua via --via |
| output reports tokens.before, tokens.after, ratio.actual | usecase.6 | metrics |
| both presses produce .min at same path | usecase.6 | format consistency |

---

## dependencies

all already installed in this repo:

| package | purpose | status |
|---------|---------|--------|
| `rhachet` | genContextBrain, BrainAtom type | installed |
| `rhachet-brains-xai` | auto-discovered by genContextBrain for xai slugs | installed |
| `rhachet-brains-anthropic` | auto-discovered by genContextBrain for anthropic slugs | installed |
| `zod` | schema for brain.ask output | installed |
| `wrapper-fns` | withRetry, withTimeout | installed |
| `js-tiktoken` | token count via cl100k_base | installed |

---

## key design decisions

1. **no domain.operations layer** — the bhrain engine is a skill-level ts file, not a domain operation. it's simple enough to live in the skill directory, following the same pattern as the llmlingua engine. this avoids over-architecture for a leaf operation.

2. **shared countTokens via eject** — `countTokens` is extracted from `compress.ts` into `compress.shared.ts` so both engines reuse the same token counter. this prevents drift and duplication.

3. **shell routes, ts computes** — the shell orchestrator handles arg parse, press family selection, file i/o, and display. the ts engines handle compression logic only and emit json. this separation keeps each layer focused.

4. **sitrep template embedded in ts** — the prompt template lives as a constant in `compress.via.bhrain.ts`. no external template files. the template is small enough to inline and benefits from version control alongside the engine.

5. **api key failfast by slug prefix** — `genContextBrain` handles brain resolution and will throw `BrainChoiceNotFoundError` if the slug is invalid or the api key is absent. the ts engine catches this and failfasts with a clear message.

6. **`genContextBrain` for brain resolution** — no manual `resolveBrainAtom` or direct `genBrainAtom` imports. `genContextBrain({ choice: { atom: brainSlug } })` auto-discovers installed brain packages and resolves the correct provider. this eliminates vendor-specific imports in the engine.

7. **`--via` is the only mech flag** — no `--mech` backwards compat. clean break.

8. **`--from` and `--into`** — `--from` for input path/glob. `--into` for explicit output path (single file only). no `--path` or positional compat.
