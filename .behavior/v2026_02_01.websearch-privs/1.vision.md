# vision: websearch.border.guard

## the outcome world

### before

the human sits at their desk, works with the mechanic on a task. the mechanic needs to look up some info — maybe the latest api docs for a library, or a stackoverflow answer, or the current cost for a cloud service.

```
mechanic: "i need to check the openai api docs for the latest embed model"
[permission request appears]
human: *clicks approve*
mechanic: "thanks, now i see gpt-4o supports..."
mechanic: "let me also check the cost page"
[permission request appears]
human: *clicks approve*
mechanic: "and one more item, the rate limits..."
[permission request appears]
human: *sighs, clicks approve*
```

the human becomes a permission-click machine. flow state evaporates. the mechanic waits. latency compounds. trust erodes — not because the mechanic is untrustworthy, but because the friction suggests risk when really... the mechanic just wants to read some docs.

### after

the human works alongside the mechanic. research happens in the background, seamlessly.

```
mechanic: "let me check the openai api docs, costs, and rate limits"
[quiet hum of network activity]
mechanic: "got it. gpt-4o embeds cost $0.00002/token with 10k rpm limit..."
```

no interruption. no permission fatigue. the mechanic researches autonomously while a border guard inspects every fetch — content either passes or it doesn't.

the human's attention is preserved for what matters: the actual work.

### the "aha" moment

the value clicks when the human realizes: "i haven't clicked 'approve websearch' in three days, but the mechanic has researched all week — and zero incidents occurred."

the security layer is invisible when content is allowed. it only surfaces when content is blocked. that's the difference between security theater (click-approve all content) and actual security (inspect at the border, deny entry to threats).

## user experience

### usecases

1. **library research** — mechanic looks up docs, changelogs, migration guides
2. **error diagnosis** — mechanic searches for error messages, stack traces
3. **api exploration** — mechanic fetches openapi specs, reads sdk docs
4. **cost comparison** — mechanic checks cloud provider cost pages
5. **best practice lookup** — mechanic reads blog posts, tutorials, guides

### contract

**input**: websearch query or url to fetch

**process** (invisible to user):
1. fetch executes
2. content passes through border guard (cheap brain.atom)
3. border guard decides: `allow` | `block`

**output by decision**:

| decision | agent receives | human action |
|----------|----------------|--------------|
| `allow` | full content | none |
| `block` | "content blocked at border" | notified, content quarantined |

### timeline

```
t+0ms     mechanic initiates webfetch
t+200ms   network fetch completes
t+400ms   border guard reviews content (fast brain.atom, ~200ms)
t+400ms   if allow: content returned to mechanic
          if block: quarantined, mechanic notified
t+0       human attention required only on block
```

total latency impact: ~200ms on a request that already has ~200ms network latency. imperceptible in practice.

## mental model

### how users describe it

> "my ai assistant can research stuff online without me as babysitter for every google search. there's a border guard that blocks sketchy content, but i've never actually seen it trigger on normal research."

### analogies

**actual border guard**: you don't approve every person who crosses. the guard inspects documents and luggage, admits or denies entry. you only hear about it when someone gets stopped. websearch.border.guard works the same way — inspect at the border, let the good through, stop the bad.

**email spam filter**: you don't manually approve every inbound email. the filter catches spam, quarantines it, and you only see your real mail. occasionally you check the spam folder.

**browser safe-browse**: chrome doesn't ask permission before every page load. it checks urls against a blocklist and warns you about phish sites. security happens in the background, surfaces only when needed.

### terminology

| user term | our term |
|-----------|----------|
| "security filter" | border guard |
| "blocked content" | quarantined content |
| "the spam folder" | `.hazardous/` directory |
| "auto-approve" | allowlisted websearch |

## evaluation

### how well does it solve the goals?

| goal | score | notes |
|------|-------|-------|
| reduce human interruption | excellent | zero interruption for allowed content |
| maintain security | strong | border guard provides defense-in-depth |
| preserve flow state | excellent | human only surfaces on block |
| low latency impact | excellent | ~200ms on already-slow network ops |
| cost efficiency | strong | cheap brain.atom (grok-code-fast-1) |

### pros

1. **flow preservation** — human attention stays on the work, not permission popups
2. **defense in depth** — every fetch is inspected, not just the ones humans remember to scrutinize
3. **audit trail** — quarantined content is preserved for human inspection
4. **graceful degradation** — if border guard is uncertain, it blocks (deny entry)
5. **latency hides** — review happens amid network wait time, not after
6. **simple model** — binary allow/block, no ambiguous middle states

### cons

1. **false positives** — legitimate content could be blocked
   - mitigation: human can inspect quarantine and release; border guard logs reason for block
2. **border guard bypass** — sophisticated attacks might fool the cheap brain.atom
   - mitigation: layered security; border guard is one layer, not the only layer
3. **cost per fetch** — every fetch incurs brain.atom cost
   - mitigation: grok-code-fast-1 is cheap (~$0.0001/review); volume is low
4. **complexity** — adds a new system component (border guard + quarantine)
   - mitigation: component is isolated; failure mode is "block and notify"

### edgecases and pit of success

| edgecase | handle | user experience |
|----------|--------|-----------------|
| border guard times out | block | "fetch timed out at border inspection" |
| border guard errors | block | "border inspection failed; entry denied" |
| very large content | truncate for review | border guard reviews first N chars |
| binary content | skip review, flag type | "binary content fetched: image/png" |
| localhost urls | block by default | "localhost urls denied at border" |
| private ip ranges | block by default | "private network urls denied at border" |

the pit of success: allowed content flows through, blocked content stops at the border, humans only engage when there's a genuine decision to make.

## open questions

1. **should quarantined content be readable by humans outside claude?**
   - yes: `.hazardous/` dir with `.gitignore`, human can `cat` directly

2. **how long to retain quarantined content?**
   - suggestion: 7 days, then auto-purge

3. **should there be a "trust this domain" allowlist?**
   - maybe: github.com, stackoverflow.com, official docs sites
   - risk: allowlists become stale; border guard should still inspect
