# research: claims for websearch.border.guard

## claim.1 = [FACT] LLMs are probabilistic and require guardrails for production use

> "LLMs are probabilistic, not deterministic. They hallucinate, leak data, and are vulnerable to prompt injection, so vanilla 'prompt → response' usage is not production-safe."

[1] LLM Guardrails - Confident AI - https://www.confident-ai.com/blog/llm-guardrails-the-ultimate-guide-to-safeguard-llm-systems

---

## claim.2 = [FACT] guardrails are essential, not optional

> "Guardrails are not optional extras—they're essential components of production-grade LLM applications. They transform unpredictable generative models into reliable, safe, and compliant systems."

[2] LLM Guardrails - Confident AI - https://www.confident-ai.com/blog/llm-guardrails-the-ultimate-guide-to-safeguard-llm-systems

---

## claim.3 = [FACT] guardrails sit between client and agent as gates

> "Guardrails sit between the client and agent, acting as gates between input, prompt construction, tool calls, and output."

[3] Datadog LLM Guardrails Best Practices - https://www.datadoghq.com/blog/llm-guardrails-best-practices/

---

## claim.4 = [SUMP] layered defense with fast checks first is best practice

> "A layered approach is common: apply fast, low-cost checks first, escalate to heavier checks only when necessary."

[4] Datadog LLM Guardrails Best Practices - https://www.datadoghq.com/blog/llm-guardrails-best-practices/

---

## claim.5 = [FACT] tool execution raises security stakes significantly

> "Tool calling and function execution significantly raise the stakes. When an LLM can trigger API calls, modify records, or interact with cloud resources, a successful attack can result in real-world impact."

[5] Datadog LLM Guardrails Best Practices - https://www.datadoghq.com/blog/llm-guardrails-best-practices/

---

## claim.6 = [FACT] over-privileged agents expand blast radius

> "If the underlying service identity is over-privileged, a compromised agent can access far more than intended. Enforcing least-privilege permissions limits blast radius by default."

[6] Datadog LLM Guardrails Best Practices - https://www.datadoghq.com/blog/llm-guardrails-best-practices/

---

## claim.7 = [FACT] performance varies dramatically by guardrail type

> "Performance considerations vary by approach: regex validation takes microseconds, neural classifiers take tens to hundreds of milliseconds, and LLM-as-judge takes seconds."

[7] Datadog LLM Guardrails Best Practices - https://www.datadoghq.com/blog/llm-guardrails-best-practices/

---

## claim.8 = [SUMP] latency above 200ms impacts interactive UX

> "For interactive systems, delays above ~200ms impact user experience."

[8] Datadog LLM Guardrails Best Practices - https://www.datadoghq.com/blog/llm-guardrails-best-practices/

note: this may not apply to websearch.border.guard since fetches already have inherent latency and research tasks are not instant-response critical.

---

## claim.9 = [KHUE] how strict should filtering be?

> "Overly strict filtering can disrupt benign user interactions, while lenient configurations risk harmful content slipping through. Effective guardrail design requires carefully calibrated thresholds and continuous monitoring to achieve optimal security without hindering user experience."

[9] Wiz LLM Guardrails - https://www.wiz.io/academy/ai-security/llm-guardrails

this is a key calibration question for websearch.border.guard: should it err toward block (more false positives) or allow (more false negatives)?

our criteria says: block by default when uncertain (security fails closed).

---

## claim.10 = [FACT] OWASP defines top LLM security threats

> "Best practices for implementing guardrails help mitigate top LLM security threats as defined by OWASP, including LLM01:2025 Prompt Injection, LLM02:2025 Sensitive Data Leakage, LLM07:2025 System Prompt Leakage, and LLM06:2025 Excessive Agency."

[10] Datadog LLM Guardrails Best Practices - https://www.datadoghq.com/blog/llm-guardrails-best-practices/

---

## claim.11 = [OPIN] guardrails add explicit contracts for predictable behavior

> "Guardrails add explicit contracts and checks so behavior is predictable and auditable."

[11] LLM Guardrails - Confident AI - https://www.confident-ai.com/blog/llm-guardrails-the-ultimate-guide-to-safeguard-llm-systems

this aligns with the wish: the border guard provides defense-in-depth that enables allowlisted websearch without human approval per request.

---

## claim.12 = [FACT] popular guardrail frameworks exist

> "Popular security libraries include LLM Guard, Prompt Armor, NeMo Guardrails, Microsoft Azure AI Content Safety, and Lakera."

[12] LLM Guardrails - Confident AI - https://www.confident-ai.com/blog/llm-guardrails-the-ultimate-guide-to-safeguard-llm-systems

note: these are full frameworks; our approach uses a simpler brain.atom pattern with a cheap model for classification.

---

## summary

| claim type | count |
|------------|-------|
| FACT | 8 |
| SUMP | 2 |
| KHUE | 1 |
| OPIN | 1 |

key insight: the industry consensus supports our approach — guardrails between agent and external content, fail-closed by default, with appropriate latency tradeoffs for the use case.
