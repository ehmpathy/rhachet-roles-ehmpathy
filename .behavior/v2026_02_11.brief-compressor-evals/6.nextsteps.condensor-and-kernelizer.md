# next steps: condensor skill + kernelizer eval

## summary

the perfeval results show that `sup:kernelize` is the critical differentiator for zero kernel loss. this means:

1. the kernelizer is now the foundation of compression quality
2. we need to evaluate the kernelizer independently
3. we need a unified "condensor" skill that composes the best pipeline

---

## step 1: create `condensor` skill

### what

a single skill that composes kernelize + compress into one operation with sensible defaults.

### why

- users shouldn't need to know the internal pipeline
- one command to compress briefs with optimal settings
- configurable for power users, pit-of-success for everyone else

### contract

```sh
# default: uses optimal pipeline from perfevals
npx rhachet run --skill condensor --from path/to/brief.md

# explicit pipeline
npx rhachet run --skill condensor --from path/to/brief.md --via "sup:kernelize, [sitrep-aggro-aware], [telegraphic]"

# plan mode (default)
npx rhachet run --skill condensor --from path/to/brief.md --mode plan

# apply mode
npx rhachet run --skill condensor --from path/to/brief.md --mode apply
```

### default config

```ts
const CONDENSOR_DEFAULTS = {
  mode: 'sup',
  methodologies: ['kernelize', 'sitrep-aggro-aware', 'telegraphic'],
  brainSlug: 'xai/grok/code-fast-1',
};
```

### implementation

```
src/domain.roles/mechanic/skills/
├── condensor/
│   ├── condensor.sh                    # shell entrypoint
│   ├── condensor.ts                    # typescript implementation
│   ├── condensor.integration.test.ts   # integration tests
│   └── briefs/
│       └── condensor.methodology.md    # methodology brief (optional)
```

### key behaviors

1. **kernel extraction** — extract kernels via `extractKernels` or `extractKernelsWithConsensus`
2. **kernel injection** — inject kernels into compression prompt (sup mode)
3. **compression** — run sitrep-aggro-aware + telegraphic passes
4. **retention check** — verify kernels retained via `checkKernelRetention`
5. **output** — emit `.min` file with compression metrics

---

## step 2: create `kernelize` skill (standalone)

### what

a dedicated skill for kernel extraction, separate from compression.

### why

- enables independent evaluation of kernelizer quality
- reusable for other use cases (summarization, index, search)
- clear responsibility boundary

### contract

```sh
# extract kernels from a brief
npx rhachet run --skill kernelize --from path/to/brief.md

# with consensus (N parallel runs)
npx rhachet run --skill kernelize --from path/to/brief.md --consensus 3

# output to specific file
npx rhachet run --skill kernelize --from path/to/brief.md --into path/to/kernels.json
```

### output format

```json
{
  "source": "path/to/brief.md",
  "kernelCount": 7,
  "kernels": [
    { "id": "k1", "concept": "all procedures use (input, context) pattern", "category": "rule" },
    { "id": "k2", "concept": "dependency injection via context argument", "category": "principle" }
  ],
  "rationale": "...",
  "consensus": { "runs": 3, "threshold": 0.5 }
}
```

### implementation

```
src/domain.roles/mechanic/skills/
├── kernelize/
│   ├── kernelize.sh                    # shell entrypoint
│   ├── kernelize.ts                    # typescript implementation
│   ├── kernelize.integration.test.ts   # basic integration tests
│   ├── kernelize.perfeval.ts           # perfeval runner
│   └── .perfevals/                     # perfeval results
```

---

## step 3: kernelizer eval framework

### what

systematic evaluation of kernelizer consistency and accuracy.

### metrics

| metric | definition | target |
|--------|------------|--------|
| **stability** | jaccard similarity of kernel sets across N runs | >0.8 |
| **precision** | % extracted kernels that are in ground truth | >0.9 |
| **recall** | % ground truth kernels that are extracted | >0.9 |
| **consensus lift** | stability improvement from consensus mode | measurable |

### eval design

```ts
interface KernelPerfeval {
  // stability: same brief, N runs
  stability: {
    briefName: string;
    runs: number;
    kernelSets: string[][];  // kernel concepts per run
    jaccardMean: number;     // mean pairwise jaccard similarity
    jaccardMin: number;
    jaccardMax: number;
  };

  // accuracy: vs human-labeled ground truth
  accuracy: {
    briefName: string;
    groundTruth: string[];   // human-labeled kernels
    extracted: string[];     // model-extracted kernels
    precision: number;
    recall: number;
    f1: number;
  };

  // consensus: single vs consensus mode
  consensus: {
    briefName: string;
    singleRunStability: number;
    consensusStability: number;
    lift: number;
  };
}
```

### ground truth briefs

create human-labeled kernel sets for representative briefs:

```
src/domain.roles/mechanic/skills/kernelize/.test/fixtures/
├── ground-truth/
│   ├── input-context-pattern.kernels.json
│   ├── dependency-injection.kernels.json
│   ├── forbid-gerunds.kernels.json
│   └── ...
```

each ground truth file:

```json
{
  "brief": "input-context-pattern",
  "source": "briefs/practices/code.prod/evolvable.procedures/rule.require.input-context-pattern.md",
  "kernels": [
    "all procedures must accept (input, context?) arguments",
    "input is a destructurable object with named keys",
    "context contains runtime dependencies",
    "positional arguments are forbidden",
    "function keyword is forbidden except for class methods"
  ],
  "labeledBy": "human",
  "labeledAt": "2026-02-13"
}
```

---

## step 4: integration

### condensor uses kernelizer

```ts
// condensor.ts
import { extractKernels, extractKernelsWithConsensus } from '../kernelize/kernelize';
import { compressViaBhrain } from '../brief.compress/compress.via.bhrain';

export const condense = async (input: {
  content: string;
  brainSlug: string;
  consensus?: number;  // if set, use consensus mode
}) => {
  // step 1: extract kernels
  const kernelResult = input.consensus
    ? await extractKernelsWithConsensus({ ...input, runs: input.consensus })
    : await extractKernels(input);

  // step 2: compress with kernel guidance
  const compressResult = await compressViaBhrain({
    content: input.content,
    brainSlug: input.brainSlug,
    mode: 'sup',
    kernels: kernelResult.kernels,
    methodologies: ['sitrep-aggro-aware', 'telegraphic'],
  });

  // step 3: verify retention
  const retentionResult = await checkKernelRetention({
    kernels: kernelResult.kernels,
    compressed: compressResult.compressed,
    brainSlug: input.brainSlug,
  });

  return {
    ...compressResult,
    kernels: kernelResult,
    retention: retentionResult,
  };
};
```

---

## timeline

| phase | scope | outcome |
|-------|-------|---------|
| **phase 1** | extract kernelize into standalone skill | `npx rhachet run --skill kernelize` works |
| **phase 2** | create kernelizer perfeval framework | stability/accuracy metrics |
| **phase 3** | create ground truth kernel sets | human-labeled validation data |
| **phase 4** | run kernelizer perfevals | baseline metrics established |
| **phase 5** | create condensor skill | unified compression skill |
| **phase 6** | integrate kernelizer into condensor | end-to-end pipeline |

---

## success criteria

1. **kernelizer stability** — jaccard similarity >0.8 across runs
2. **kernelizer accuracy** — precision/recall >0.9 vs ground truth
3. **condensor usability** — one command compresses with optimal settings
4. **condensor quality** — zero kernel loss on standard briefs
5. **eval coverage** — both skills have perfeval suites

---

## open questions

1. **consensus runs** — is 3 the right default? or should we test 5?
2. **ground truth labels** — who labels? how many briefs?
3. **kernel categories** — are the current categories (rule, principle, definition, pattern, constraint) sufficient?
4. **cross-domain stability** — does kernelizer work equally well on all brief types?
