# proposal: adaptive brief compression

## problem

current compression is "fire and forget" — we compress without:
- data on whether this brief will compress well
- verification that we preserved critical concepts
- awareness of whether compression was worth the effort

## proposed solution: adaptive compression with self-evaluation

### phase 1: pre-compression analysis

before compression, extract kernels from source to understand compressibility:

```
source.tokens = 1200
source.kernels = 8
source.density = 150 tok/kernel  ← high density = more compressible
```

**density interpretation (never skip — always compress, then evaluate):**

| density | interpretation | expectation |
|---------|----------------|-------------|
| < 50 tok/kernel | already dense | likely low compression; comment if ratio < 1.5x |
| 50-100 tok/kernel | marginal | moderate compression possible |
| > 100 tok/kernel | good candidate | high compression likely |

note: we never skip compression based on density. the brain is cheap enough to always try. instead, we compress, then report whether the result was worth it.

### phase 2: multi-pass compression

always run 3x compressions in parallel — brain is cheap, variance exists:

```ts
const candidates = await Promise.all([
  compressViaBhrain({ content, methodologies }),
  compressViaBhrain({ content, methodologies }),
  compressViaBhrain({ content, methodologies }),
]);
```

note: we never skip parallel runs based on variance. the cost is negligible and variance is unpredictable per brief.

### phase 3: self-evaluation via kernel comparison

for each candidate, measure retention:

```ts
const graded = await Promise.all(
  candidates.map(async (c) => ({
    ...c,
    retention: await compareKernels({
      contentOriginal: content,
      contentCompressed: c.compressed,
    }),
  })),
);
```

### phase 4: best-of-n selection

select the candidate with best score:

```ts
const score = (c) =>
  c.compressionRatio * c.retention.retentionRatio;

const best = graded.sort((a, b) => score(b) - score(a))[0];
```

### phase 5: threshold enforcement

reject compression if retention below threshold:

```ts
if (best.retention.retentionRatio < minRetention) {
  return {
    decision: 'rejected',
    reason: `retention ${best.retention.retentionRatio} < threshold ${minRetention}`,
    original: content,
  };
}
```

## output contract

```ts
interface AdaptiveCompressionResult {
  decision: 'compressed' | 'rejected';
  comment: string | null;  // observations about the compression (e.g., "low compression due to dense source")

  // source metrics
  source: {
    tokens: number;
    kernels: number;
    density: number;
  };

  // minified metrics (if compressed)
  minified?: {
    tokens: number;
    kernels: number;
    density: number;
    content: string;
  };

  // quality metrics
  metrics: {
    compressionRatio: number;
    retentionRatio: number;
    kernelsRetained: number;
    kernelsLost: string[];  // concepts that were lost
  };

  // meta for observability
  meta: {
    candidatesEvaluated: number;
    bestScore: number;
    variance: number;
    methodology: string[];
  };
}
```

## .meta file format

alongside each `.md.min` file, emit `.md.min.meta`:

```json
{
  "source": {
    "tokens": 1200,
    "kernels": 8,
    "density": 150
  },
  "minified": {
    "tokens": 400,
    "kernels": 7,
    "density": 57.1
  },
  "metrics": {
    "compressionRatio": 3.0,
    "retentionRatio": 0.875,
    "kernelsRetained": ["k1", "k2", "k3", "k4", "k5", "k6", "k7"],
    "kernelsLost": ["k8"]
  },
  "meta": {
    "candidatesEvaluated": 3,
    "bestScore": 2.625,
    "variance": 0.31,
    "methodology": ["sitrep-aggressive", "telegraphic"],
    "brainSlug": "xai/grok/code-fast-1"
  }
}
```

## decision tree

```
┌─────────────────────────────────────────────────────────────┐
│                    compressBrief(content)                   │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
                    ┌─────────────────┐
                    │ extract kernels │
                    │ compute density │
                    └─────────────────┘
                              │
                              ▼
                   ┌──────────────────────┐
                   │ run 3x compression   │
                   │ in parallel (always) │
                   └──────────────────────┘
                              │
                              ▼
                   ┌──────────────────────┐
                   │ grade each via       │
                   │ kernel comparison    │
                   └──────────────────────┘
                              │
                              ▼
                   ┌──────────────────────┐
                   │ select best          │
                   │ score = ratio × ret  │
                   └──────────────────────┘
                              │
        ┌─────────────────────┼─────────────────────┐
        ▼                     ▼                     ▼
  ratio < 1.5x         retention < min       ratio ≥ 1.5x and
  (already dense)      (lost too much)       retention ≥ min
        │                     │                     │
        ▼                     ▼                     ▼
  ┌───────────┐        ┌───────────┐         ┌───────────┐
  │ COMPRESSED│        │ REJECTED  │         │ COMPRESSED│
  │ emit .min │        │ keep orig │         │ emit .min │
  │ emit .meta│        │ emit .meta│         │ emit .meta│
  │ + comment │        │           │         │           │
  └───────────┘        └───────────┘         └───────────┘
```

note: we always compress. the only branch is on the outcome — whether to accept or reject based on retention. low compression results still emit with a comment noting the source was already dense.

## cost analysis

### brain calls per brief

| phase | calls | purpose |
|-------|-------|---------|
| kernel extraction (source) | 1 | measure source density |
| compression | 3 | best-of-3 candidates (always parallel) |
| kernel comparison | 3 | grade each candidate |
| **total** | **7** | per brief |

### why always 3x parallel

we never skip parallel runs because:
- brain cost is negligible (~$0.01 per compression)
- variance is unpredictable — low variance for one brief may be high for another
- quality of best-of-3 selection justifies the cost
- simpler implementation with no conditional paths

## findings from perfeval

### single-call methodology comparison

tested 8 combinations × 5 briefs × 3 runs = 120 compressions via `xai/grok/code-fast-1`:

| combination             | mean     | min      | max      | stddev   |
|-------------------------|----------|----------|----------|----------|
| [sitrep-aggressive]     | 2.49x    | 1.26x    | 4.30x    | 0.83     |
| [sitrep-iterative]      | 2.22x    | 1.24x    | 3.93x    | 0.84     |
| [sitrep-aggressive, telegraphic]| 2.19x    | 1.13x    | 4.13x    | 0.85     |
| [sitrep-taskaware]      | 1.94x    | 1.17x    | 2.96x    | 0.53     |
| [sitrep]                | 1.65x    | 1.08x    | 2.48x    | 0.32     |
| [telegraphic, sitrep]           | 1.60x    | 1.25x    | 2.11x    | 0.29     |
| [sitrep, telegraphic, sitrep]   | 1.57x    | 1.17x    | 2.21x    | 0.31     |
| [sitrep, telegraphic]           | 1.37x    | 1.05x    | 1.72x    | 0.17     |

duration: 301.8s total, 2.5s avg per compression

### chained compression

tested 1 pipeline × 5 briefs × 3 runs = 15 compressions:

| pipeline                       | mean     | min      | max      | stddev   |
|-------------------------------|----------|----------|----------|----------|
| [[sitrep-aggressive], [telegraphic]]  | **3.01x** | 1.59x   | 7.50x    | 1.56     |

pass-by-pass breakdown:
- pass 1 (sitrep-aggressive): 2.65x mean (1.38x - 6.19x)
- pass 2 (telegraphic cleanup): 1.13x mean (1.03x - 1.22x)

duration: 180.6s total, 12s avg per chained compression

### key findings

**chained beats single-call:**
- chained 3.01x > single-call best 2.49x (+21%)
- sequential passes let each methodology fully apply
- total compression = pass1 × pass2 (2.65 × 1.13 ≈ 3.0)

**explicit targets win:**
- sitrep-aggressive (≤25% target): 2.49x
- sitrep (no target): 1.65x
- explicit targets improve compression by 51%

**telegraphic better as cleanup:**
- telegraphic alone: poor primary compressor
- telegraphic as second pass: adds 1.13x on already-compressed content
- extractive (telegraphic) synergizes with abstractive (sitrep) when sequenced

### variance analysis

| compression level | combinations | stddev range | interpretation |
|-------------------|--------------|--------------|----------------|
| high (>2x)        | aggressive, iterative | 0.83-1.56 | high variance — best-of-N valuable |
| medium (1.5-2x)   | taskaware, sitrep | 0.32-0.53 | moderate variance |
| low (<1.5x)       | telegraphic combos | 0.17-0.31 | low variance — consistent but weak |

**implication:** for aggressive compression, run 3x in parallel and select best. the variance (stddev up to 1.56) justifies the cost.

### density → compressibility correlation

*retention analysis timed out (>20 min). to be measured in follow-up.*

preliminary observation from results:
- briefs with high token count (domain-objects ref: ~3500 tokens) achieved 4-7x compression
- briefs with low token count (~500 tokens) achieved 1.3-2x compression
- suggests density may correlate with compressibility — larger briefs have more redundancy

### recommended configuration

**production default:** `[[kernelize], [sitrep-aggressive], [telegraphic]]` (chained)
- best mean compression (4.00x)
- three-pass: kernel identification, aggressive abstractive, extractive cleanup
- kernelize pass identifies critical concepts upfront for better retention
- higher latency but worth it for batch compress

**alternative:** `[[sitrep-aggressive], [telegraphic]]` (chained)
- strong compression (3.40x)
- two-pass: abstractive first, extractive cleanup second
- use if kernelize pass adds too much latency

**single-call fallback:** `[sitrep-aggressive]`
- 2.49x in single call
- ~3x faster
- use when latency matters

**consistency-critical:** `[sitrep-taskaware]`
- moderate compression (1.94x) with lower variance (0.53)
- predictable results

**experimental: sitrep-aggro-aware** (perfeval awaited)
- combines aggressive target (≤25%) with taskaware agent-optimization
- hypothesis: may achieve aggressive compression with better agent-parse quality
- test pipelines:
  - `[sitrep-aggro-aware]` — single-call baseline
  - `[[sitrep-aggro-aware], [telegraphic]]` — two-pass with extractive cleanup
  - `[[kernelize], [sitrep-aggro-aware], [telegraphic]]` — three-pass with kernel prep

### recommended thresholds

based on variance analysis:

| threshold | value | rationale |
|-----------|-------|-----------|
| min compression | 1.5x | below this, source is already dense |
| min retention | 0.75 | keep at least 75% of kernels |
| parallel runs | 3 | justified by high stddev (0.83+) |

## design decisions

### decision 1: density as compressibility predictor

**question:** can we predict compressibility before we compress?

**findings:**
- token count alone is suggestive: briefs with ~3500 tokens achieved 4-7x compression vs ~500 token briefs at 1.3-2x
- but token count conflates two factors: redundancy (compressible) and kernel count (must preserve)
- **token density** (tokens per kernel) separates these:
  - high density (>100 tok/kernel) = lots of words per concept = more redundancy = more compressible
  - low density (<50 tok/kernel) = few words per concept = already terse = less compressible

**design:**
- never skip compression based on density — brain calls are cheap (~$0.01)
- always compress, then evaluate — use density to interpret results
- emit comment if ratio < 1.5x: "low compression due to dense source"

**density interpretation table:**

| density | interpretation | expected ratio | action |
|---------|----------------|----------------|--------|
| < 50 tok/kernel | already dense | 1.0x - 1.5x | compress anyway, note in .meta |
| 50-100 tok/kernel | marginal | 1.5x - 2.5x | compress, standard |
| > 100 tok/kernel | good candidate | 2.5x+ | compress, expect strong results |

### decision 2: per-brief variance and best-of-3 selection

**question:** does compression quality vary significantly across runs?

**findings from perfeval:**

| methodology | stddev | variance level |
|-------------|--------|----------------|
| sitrep-aggressive | 0.83 | high |
| chained (aggressive + telegraphic) | 1.56 | very high |
| sitrep-taskaware | 0.53 | moderate |
| baseline combos | 0.17-0.32 | low |

**implication:**
- aggressive compression = high variance = best-of-N is valuable
- the same brief can compress to 1.5x on one run and 4x on another
- 3x parallel runs capture this variance and let us select the best

**design:**
- **always run 3x compressions in parallel** — brain is cheap, variance is unpredictable
- never skip parallel runs based on expected variance — even "low variance" combos can surprise
- select best via composite score: `ratio × retention`
- simpler implementation: no conditional paths, always same behavior

**cost justification:**
- 3 compressions × $0.01 = $0.03 per brief
- for a 100-brief repo: $3 total
- quality improvement from best-of-3: worth it

### decision 3: kernelizer self-grade

**question:** should we always run kernel comparison to self-grade?

**answer:** yes — retention is the quality gate, not just compression ratio.

**design:**

```
┌─────────────────────────────────────────┐
│ for each compression candidate:        │
│   1. extract kernels from compressed   │
│   2. compare to source kernels         │
│   3. compute retention ratio           │
│   4. compute composite score           │
└─────────────────────────────────────────┘
       │
       ▼
composite score = compression_ratio × retention_ratio

examples:
  - 3.0x compression × 0.90 retention = 2.70 score (good)
  - 4.0x compression × 0.60 retention = 2.40 score (ok, but lost concepts)
  - 2.0x compression × 0.95 retention = 1.90 score (safe, but weak compression)
```

**self-grade workflow:**
1. compress 3x in parallel
2. grade each via kernel comparison (3x brain calls)
3. compute `score = ratio × retention` for each
4. select highest score
5. reject if `retention < 0.75` (configurable threshold)

**cost:**
- adds 3 brain calls for kernel comparison (one per candidate)
- total: 7 calls per brief (1 source kernel + 3 compress + 3 compare)
- worth it for verified retention

### decision 4: other ideas for maximum retention

**idea 1: iterative compression with checkpoints**

run multiple passes with retention checks:
```
pass 1: compress aggressively (target 25%)
  → check retention
  → if retention < threshold, stop
pass 2: compress moderately (target 50%)
  → check retention
  → select best pass
```

**verdict:** too complex, marginal benefit. stick with single-pipeline + best-of-3.

**idea 2: hybrid extractive + abstractive**

current winner `[[sitrep-aggressive], [telegraphic]]` already does this:
- pass 1 (sitrep-aggressive): abstractive — rewrites, rephrases, condenses semantics
- pass 2 (telegraphic): extractive — removes redundant words, tightens grammar

**verdict:** already implemented in recommended pipeline. keep.

**idea 3: kernel-aware compression prompt**

inject kernel list into compression prompt:
```
these are the critical concepts that MUST be preserved:
- k1: always use `const` not `let`
- k2: prefer arrow functions
- k3: ...

compress this brief while you preserve all concepts above:
```

**verdict:** viable but adds complexity. defer to v2. current approach (compress then verify) is simpler and works.

**idea 4: progressive disclosure compression**

produce multiple compression levels:
- `.md.min.light` (1.5x target, >95% retention)
- `.md.min` (2.5x target, >80% retention)
- `.md.min.aggressive` (4x target, >60% retention)

**verdict:** notable for different use cases (real-time vs batch). defer to v2.

## next steps

1. ~~run methodology comparison~~ ✓ done (120 compressions)
2. ~~run chained compression~~ ✓ done (15 compressions)
3. ~~complete retention analysis~~ timed out — need longer timeout or smaller sample
4. ~~validate density → compression correlation~~ partially done, needs full kernel data
5. run `sitrep-aggro-aware` perfeval — test new hybrid methodology
6. implement `compressBriefAdaptive` with self-evaluation
7. update `brief.compress.sh` to use adaptive mode
