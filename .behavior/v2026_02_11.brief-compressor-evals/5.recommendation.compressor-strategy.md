# recommendation: optimal compressor strategy

## summary

based on perfeval results from 2026-02-13.6 (1272 compressions across 53 pipeline combinations), the optimal strategy prioritizes:

- **P1**: minimize kernel loss (preserve semantic signal)
- **P2**: maximize density (compress tokens)

## winner: `sup:kernelize, [sitrep-aggro-aware], [telegraphic]`

this pipeline achieves **zero kernel loss** with solid compression:

| metric | value | interpretation |
|--------|-------|----------------|
| kern.Δ | **+0.0** | zero kernel loss |
| kern.σ | **0.0** | zero variance (consistent) |
| dens.Δ | **+3.3** | +3.3 density improvement |
| tok.Δ | **-1202** | avg 1202 tokens removed |

the only pipeline in the evaluation that achieves both zero kernel loss AND zero variance.

---

## how it works

### pipeline breakdown

```
sup:kernelize, [sitrep-aggro-aware], [telegraphic]
│
├── sup:kernelize
│   └── extract kernels as system prompt preamble
│   └── guides compressor on what to preserve
│
├── [sitrep-aggro-aware]
│   └── aggressive compression with kernel awareness
│   └── targets ≤25% of original while it protects signal
│
└── [telegraphic]
    └── extractive cleanup pass
    └── removes syntactic noise without semantic loss
```

### why it wins

1. **kernel extraction first** — `sup:kernelize` pre-identifies critical concepts before compression
2. **aggro-aware balance** — `sitrep-aggro-aware` is aggressive but respects the kernel list
3. **telegraphic cleanup** — removes articles, filler words, verbose phrases
4. **sup mode** — kernels as preamble (not chained pass) gives compressor full context

---

## tradeoff options

if higher compression is acceptable with minimal kernel loss:

| pipeline | dens.Δ | kern.Δ | kern.σ | use case |
|----------|--------|--------|--------|----------|
| `sup:kernelize, [sitrep-aggro-aware], [telegraphic]` | +3.3 | **+0.0** | **0.0** | **production default** |
| `[[sitrep-iterative], [telegraphic]]` | +6.6 | -0.9 | 1.0 | max density, ~1 kernel loss |
| `sup:kernelize, [sitrep-iterative], [telegraphic]` | +3.3 | -0.4 | 1.0 | same density, slight loss |
| `sup:kernelize, [sitrep], [telegraphic]` | +1.1 | +0.0 | 0.0 | conservative, zero loss |

### when to accept kernel loss

- briefs with high kernel count (10+) can tolerate -1 to -2 loss
- briefs with low kernel count (3-5) should use zero-loss pipeline
- high-value briefs (rules, contracts) should always use zero-loss

---

## production config

```ts
// recommended default
const COMPRESSOR_CONFIG = {
  mode: 'sup',
  methodologies: ['kernelize', 'sitrep-aggro-aware', 'telegraphic'],
};

// usage
await compressViaBhrain({
  content: briefContent,
  brainSlug: 'xai/grok/code-fast-1',
  ...COMPRESSOR_CONFIG,
});
```

---

## key lessons

### what works

| pattern | why |
|---------|-----|
| `sup:` prefix | kernels as preamble gives full context |
| `sitrep-aggro-aware` | balances aggression with preservation |
| `telegraphic` as final pass | safe cleanup, no semantic loss |
| chained passes | each methodology fully applies |

### what fails

| pattern | why |
|---------|-----|
| `tsc` alone | inconsistent, high variance |
| `sitrep-aggressive` alone | loses kernels under pressure |
| single-call combos | methodologies compete rather than sequence |
| `kernelize` as chained pass | less effective than `sup:` mode |

---

## metrics glossary

| metric | definition |
|--------|------------|
| `dens.Δ` | density change (kernels per 100 tokens improvement) |
| `kern.Δ` | kernel count change (0 = no loss, negative = loss) |
| `kern.σ` | kernel loss standard deviation (0 = consistent) |
| `tok.Δ` | token count change (negative = compression) |

---

## source data

- **eval**: 2026-02-13.6
- **brain**: xai/grok/code-fast-1
- **combinations**: 53 pipelines
- **briefs**: 8 representative samples
- **runs**: 3 per combination
- **total compressions**: 1272
- **duration**: 1261s

see `.perfevals/2026-02-13.6.evals.md` for granular results.
