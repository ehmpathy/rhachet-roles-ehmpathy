# blueprint: kernelize skill

## overview

the kernelize skill extracts semantic kernels from briefs, with optional consensus mode for stability. it reuses and ejects the kernel extraction logic from `brief.compress/extractKernels.ts` into a standalone skill.

---

## filediffs

```
src/domain.roles/mechanic/skills/
├── kernelize/
│   ├── [+] kernelize.sh                           # shell entrypoint
│   ├── [+] kernelize.ts                           # typescript implementation
│   ├── [+] kernelize.integration.test.ts          # contract tests
│   ├── [+] kernelize.perfeval.ts                  # perfeval runner
│   ├── [+] output.sh                              # turtle vibes output helpers
│   ├── [+] .perfevals/                            # perfeval results
│   │   └── [+] .gitkeep
│   ├── [+] .test/
│   │   └── [+] fixtures/
│   │       └── [+] ground-truth/
│   │           ├── [+] input-context-pattern.kernels.json
│   │           ├── [+] dependency-injection.kernels.json
│   │           ├── [+] forbid-gerunds.kernels.json
│   │           └── [+] domain-objects-ref.kernels.json
│   └── [+] __snapshots__/
│       └── [+] kernelize.integration.test.ts.snap
│
├── brief.compress/
│   ├── [→] extractKernels.ts                      # eject to shared location
│   ├── [~] extractKernels.integration.test.ts     # update imports
│   ├── [~] compress.via.bhrain.ts                 # update imports
│   └── [~] compress.via.bhrain.perfeval.integration.test.ts  # update imports
```

---

## codepaths

```
src/domain.roles/mechanic/skills/kernelize/

kernelize.sh
├── [+] parse args (--from, --consensus, --threshold, --into, --mode)
├── [+] validate inputs
├── [+] delegate to kernelize.ts via npx tsx
└── [+] format output via output.sh

kernelize.ts
├── [+] parseArgs()
├── [+] runKernelize()
│   ├── [←] extractKernels()           # reuse from ejected module
│   ├── [←] extractKernelsWithConsensus()  # reuse from ejected module
│   └── [+] formatOutput()
└── [+] main()

kernelize.perfeval.ts
├── [+] EVAL_MATRIX                    # N × T configurations
├── [+] BRIEFS                         # representative brief set
├── [+] runStabilityEval()             # jaccard across N runs
├── [+] runAccuracyEval()              # precision/recall vs ground truth
├── [+] computeJaccard()               # set similarity
├── [+] computePrecisionRecall()       # vs ground truth
└── [+] emitPerfevalReport()           # json + markdown output

kernelize.integration.test.ts
├── [+] given('a brief with semantic content')
│   ├── [+] when('kernelize without --consensus')
│   │   ├── [+] then('returns kernel list')
│   │   └── [+] then('completes within timeout')
│   └── [+] when('kernelize with --consensus 3')
│       ├── [+] then('returns consensus metadata')
│       └── [+] then('returns majority kernels')
├── [+] given('an empty brief')
│   └── [+] when('kernelize')
│       └── [+] then('returns empty kernels')
└── [+] given('ground truth brief')
    └── [+] when('kernelize')
        ├── [+] then('precision > 0.9')
        └── [+] then('recall > 0.9')
```

---

## ejected module

```
src/domain.operations/kernelize/

[+] extractKernels.ts                    # ejected from brief.compress
├── [○] kernelSchema                     # retain
├── [○] ConceptKernel                    # retain
├── [○] KernelExtractionResult           # retain
├── [○] extractKernels()                 # retain
├── [○] extractKernelsWithConsensus()    # retain
├── [○] checkKernelRetention()           # retain
└── [○] compareKernels()                 # retain (deprecated)

[+] extractKernels.test.ts               # unit tests for ejected module
├── [+] given('extractKernels')
│   └── [+] when/then for schema validation
├── [+] given('extractKernelsWithConsensus')
│   └── [+] when/then for consensus logic
└── [+] given('checkKernelRetention')
    └── [+] when/then for retention check
```

---

## domain objects

```ts
// ConceptKernel — already exists in extractKernels.ts
interface ConceptKernel {
  id: string;                                    // k1, k2, ...
  concept: string;                               // the distinct concept
  category: 'rule' | 'principle' | 'definition' | 'pattern' | 'constraint';
}

// KernelExtractionResult — already exists
interface KernelExtractionResult {
  kernels: ConceptKernel[];
  rationale: string;
  kernelCount: number;
}

// KernelizeOutput — new, for skill output
interface KernelizeOutput {
  source: string;                                // input file path
  kernelCount: number;
  kernels: ConceptKernel[];
  rationale: string;
  consensus?: { runs: number; threshold: number };
}

// GroundTruthKernels — new, for eval fixtures
interface GroundTruthKernels {
  brief: string;                                 // brief identifier
  source: string;                                // source file path
  kernels: string[];                             // human-labeled concepts
  labeledBy: 'human';
  labeledAt: string;                             // ISO date
}

// PerfevalResult — new, for eval output
interface PerfevalResult {
  config: { runs: number; threshold: number };
  stability: { jaccard: number; samples: number };
  accuracy: { precision: number; recall: number; f1: number };
  latency: { mean: number; p95: number };
  cost: { tokens: number };
}
```

---

## contracts

### skill contract (shell)

```sh
# single extraction
npx rhachet run --skill kernelize --from path/to/brief.md

# consensus mode
npx rhachet run --skill kernelize --from path/to/brief.md --consensus 3

# custom threshold
npx rhachet run --skill kernelize --from path/to/brief.md --consensus 5 --threshold 0.7

# output to file
npx rhachet run --skill kernelize --from path/to/brief.md --into path/to/kernels.json
```

### typescript contract

```ts
// kernelize.ts
export const runKernelize = async (input: {
  from: string;
  consensus?: number;
  threshold?: number;
  into?: string;
}): Promise<KernelizeOutput>
```

### perfeval contract

```ts
// kernelize.perfeval.ts
export const runPerfevals = async (input: {
  briefs: string[];
  matrix: Array<{ runs: number; threshold: number }>;
  groundTruthDir: string;
}): Promise<PerfevalResult[]>
```

---

## test coverage

| scope | file | coverage |
|-------|------|----------|
| unit | `extractKernels.test.ts` | schema validation, consensus logic |
| integration | `kernelize.integration.test.ts` | end-to-end skill invocation |
| integration | `kernelize.perfeval.ts` | stability and accuracy evals |
| acceptance | (via blackbox criteria) | cli contract verification |

---

## eval matrix

| N (runs) | T (threshold) | expected |
|----------|---------------|----------|
| 1 | n/a | baseline stability |
| 3 | 0.5 | majority consensus |
| 3 | 0.7 | strict consensus |
| 5 | 0.5 | broader sample |
| 5 | 0.7 | strict + broad |
| 7 | 0.5 | plateau check |

metrics per cell:
- stability (jaccard across repeated evals)
- precision/recall vs ground truth
- latency (wall clock)
- cost (tokens)

---

## ground truth briefs

| brief | source | kernel count (est) |
|-------|--------|-------------------|
| input-context-pattern | `rule.require.input-context-pattern.md` | 4-6 |
| dependency-injection | `rule.require.dependency-injection.md` | 5-7 |
| forbid-gerunds | `rule.forbid.gerunds.md` | 3-5 |
| domain-objects-ref | `ref.package.domain-objects.[ref].md` | 8-12 |

human labels required before accuracy evals can run.

---

## dependencies

| dependency | source | status |
|------------|--------|--------|
| `extractKernels` | `brief.compress/extractKernels.ts` | eject to shared |
| `extractKernelsWithConsensus` | `brief.compress/extractKernels.ts` | eject to shared |
| `genContextBrain` | `rhachet` | available |
| `withTimeout` | `wrapper-fns` | available |
| `zod` | npm | available |

---

## phases

| phase | scope | outcome |
|-------|-------|---------|
| 0 | eject extractKernels to shared location | imports updated |
| 1 | create kernelize skill shell + ts | `--skill kernelize` works |
| 2 | add consensus params | `--consensus N --threshold T` works |
| 3 | create ground truth fixtures | 4 human-labeled briefs |
| 4 | create perfeval infrastructure | stability + accuracy metrics |
| 5 | run eval matrix | optimal N, T identified |
| 6 | document findings | perfeval report |
