wish =

with the prior work , we 've successfully conducted evals on a variety of different compression pipelines, which include kernalization and multistep multipart method briefs

we now want to enable these pipelines to be used via a skill interface


specifically, we want to leverage the extant skills of compress and kernelize 

to now enable callers to invoke a skill called 'condense' in order to densify their input briefs while still retaining the kernels from it

---

specifically, this densify skill should

1. always kernelize the inputs, so we can self measure
	- if the brief is not kernalizable with stable kernel clusters, we should fail fast, as that brief is too ambiguous. if its too ambiguous to even kernelize stably, its defo too ambiguous to compress

2. support an adhoc input of a pipelne, in notation 
	--supply $supplySpec 
	--press  $pressSpec
	--verify $verifySpec 

where supply spec defines what supply operations are done beforehand , if any (e.g., kernelize)

where press spec defines what press operations rae done on hand (e.g., [[req-kernels, sitrep-aggressive], [req-kernels, telegraphic], [req-kernels, telegraphic]]


where verify spec defines what verify aoperations are done after hand, if any (e.g., restore)

---

we also need to ensure that this condense operation will
1. failfast if it cant be condensed for any reason
	- if cant do any of the spec opperations (supply, press, verify) it should failfast and explain why
2. selfgrade the output 
	- it should self meausre the dens.delta, kern.delta
	- it should run in N attempts on every input and selfgrade the variance of each too (default to N=3)

---

see src/domain.roles/mechanic/skills/brief.compress/briefs/recommended-pipelines.md

for the top 5 pipelines to recommend in --help list examples

---

also, lets be clear that we want to productionalize the codepath that was built in the evals

i.e., properly decompose it and make the contracts stable and maintainable and aligned with our best practices


