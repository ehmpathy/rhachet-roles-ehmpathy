# vision: condense skill

## the outcome world

### before

compression quality is opaque. you invoke `brief.compress` and get a smaller file â€” but did it preserve the critical concepts? you don't know until an agent fails to understand the brief.

```sh
# compress with no quality visibility
npx rhachet run --skill brief.compress --from rule.md --via bhrain/sitrep
# output: tokens.before=1200, tokens.after=450, ratio=2.7x
# but... did we lose anything important?
```

checking retention requires a separate kernelize step, manual comparison, and hope.

### after

`condense` is a single atomic operation that compresses AND self-grades:

```sh
npx rhachet run --skill condense \
  --from rule.md \
  --onPress '[[req-kernels, sitrep-aggressive], [telegraphic]]'
```

output:
```
ğŸ¢ shell yeah!

condense
â”œâ”€â”€ from: rule.md
â”œâ”€â”€ into: rule.md.min
â”œâ”€â”€ pipeline: sup:[kernelize], [[req-kernels, sitrep-aggressive], [telegraphic]]
â”œâ”€â”€ attempts: 3
â”œâ”€â”€ result
â”‚   â”œâ”€â”€ dens.Î”: +5.1
â”‚   â”œâ”€â”€ dens.Ïƒ: 1.9
â”‚   â”œâ”€â”€ kern.Î”: -0.3
â”‚   â”œâ”€â”€ kern.Ïƒ: 0.1
â”‚   â””â”€â”€ tokens: 1200 â†’ 412
â””â”€â”€ quality: âœ“ stable (Ïƒ < 3.0)
```

the "aha" moment: you see the quality metrics inline. if `kern.Î”` is negative, you know kernels were lost. if `dens.Ïƒ` is high, you know the pipeline is unstable. no guessing.

### day-in-the-life

1. mechanic edits a brief
2. mechanic runs `condense` with recommended pipeline
3. mechanic sees quality metrics inline
4. if metrics are good â†’ brief is production-ready
5. if metrics are bad â†’ mechanic adjusts pipeline or revises brief

no separate validation step. no manual kernel comparison. one command, full visibility.

---

## user experience

### usecase.1 = condense with recommended pipeline

```sh
# use the default recommended pipeline (highest stability)
npx rhachet run --skill condense --from briefs/rule.md

# explicitly specify pipeline
npx rhachet run --skill condense \
  --from briefs/rule.md \
  --onPress '[[req-kernels, sitrep-aggressive], [telegraphic]]'
```

### usecase.2 = lossless compression

```sh
# zero kernel loss pipeline
npx rhachet run --skill condense \
  --from briefs/critical-rule.md \
  --onPress '[[req-kernels, sitrep-aggressive], [req-kernels, sitrep-taskaware], [req-kernels, telegraphic]]'
```

this 3-step pipeline with `req-kernels` at each step achieves zero kernel loss (kern.Î” = 0.0).

### usecase.3 = max compression with restore

```sh
# aggressive compression with kernel restoration
npx rhachet run --skill condense \
  --from briefs/verbose-ref.md \
  --onPress '[[sitrep-aggressive], [telegraphic]]' \
  --onVerify restore
```

the `--onVerify restore` flag recovers any lost kernels from the source.

### usecase.4 = batch condensation

```sh
# condense all briefs in a directory
npx rhachet run --skill condense \
  --from 'briefs/**/*.md' \
  --onPress '[[req-kernels, sitrep-aggressive], [telegraphic]]'
```

### usecase.5 = unstable brief detection

```sh
npx rhachet run --skill condense --from briefs/ambiguous.md
```

output (failure):
```
ğŸ¢ bummer dude...

condense
â”œâ”€â”€ from: briefs/ambiguous.md
â”œâ”€â”€ error: kernelization unstable
â”‚   â”œâ”€â”€ attempts: 3
â”‚   â”œâ”€â”€ stability.meanJaccard: 0.42 (required: â‰¥0.7)
â”‚   â”œâ”€â”€ stability.minJaccard: 0.31
â”‚   â””â”€â”€ rationale: extracted kernels vary significantly across runs
â””â”€â”€ suggestion: revise brief to reduce ambiguity before compression
```

the brief is too ambiguous to kernelize stably â€” and therefore too ambiguous to compress safely.

note: this uses the same `ConsensusStability` metrics from `extractKernelsWithConsensus`:
- `meanJaccard` â€” average pairwise jaccard similarity of kernel cluster sets
- `minJaccard` / `maxJaccard` â€” range across all pairwise comparisons
- threshold â‰¥0.7 means runs must agree on at least 70% of kernel clusters

---

## contract

### arguments

| arg | type | default | description |
|-----|------|---------|-------------|
| `--from` | path \| glob | required | input file(s) |
| `--into` | path | `{from}.min` | output path (single file only) |
| `--onSupply` | `kernelize` \| null | `kernelize` | supply operation before compression |
| `--onPress` | string | recommended | press pipeline spec (see below) |
| `--onVerify` | `restore` \| null | null | post-verification operation (restores lost kernels) |
| `--attempts` | number | `3` | runs per input for variance measurement |
| `--mode` | `plan` \| `apply` | `apply` | preview or emit |
| `--brain` | string | `xai/grok/code-fast-1` | brain provider for compression |

### onPress spec format

onPress spec is a JSON array of steps, where each step is an array of briefs:

```
[[step1-brief1, step1-brief2], [step2-brief1], ...]
```

briefs (from registry at `skills/brief.compress/briefs/`):
- `sitrep` â€” baseline sitrep compression
- `sitrep-aggressive` â€” aggressive compression target
- `sitrep-iterative` â€” two-pass internal refinement
- `sitrep-taskaware` â€” optimized for agent context
- `telegraphic` â€” telegraphic semantic compression
- `req-kernels` â€” inject extracted kernels into prompt

supply operations (from registry at `skills/brief.condense/supply/`):
- `kernelize` â€” extract concept kernels before compression

verify operations (from registry at `skills/brief.condense/verify/`):
- `restore` â€” restore lost kernels from source after compression

### output metrics

| metric | definition | target |
|--------|------------|--------|
| `dens.Î”` | density improvement (chars/kernel ratio change) | higher is better |
| `dens.Ïƒ` | density variance across attempts | < 3.0 is stable |
| `kern.Î”` | kernel count change (negative = loss) | > -1 is acceptable |
| `kern.Ïƒ` | kernel variance across attempts | 0.0 is ideal |
| `tokens` | token count before â†’ after | lower after is better |

### exit codes

| code | meaning |
|------|---------|
| 0 | success |
| 1 | generic error |
| 2 | kernelization unstable (brief too ambiguous) |
| 3 | kernel loss exceeded threshold |
| 4 | verification failed |

---

## mental model

### analogy: cooking

| cooking | condense |
|---------|----------|
| prep ingredients | **onSupply**: extract kernels |
| cook | **onPress**: apply compression steps |
| plate + taste test | **onVerify**: check kernel retention |

you don't serve food without tasting it. you don't serve a compressed brief without checking kernel retention.

### analogy: nutrition label

kernels are the "nutrition" of a brief â€” the essential concepts that must survive compression. density is the "calorie density" â€” more value per token.

the condense skill is like a nutrition label for your compressed brief: it tells you exactly what survived and what was lost.

### terminology

| user term | internal term |
|-----------|---------------|
| "compress with quality check" | condense |
| "critical concepts" | kernels |
| "compression ratio" | density |
| "did it lose anything?" | kern.Î” |
| "is it consistent?" | Ïƒ (variance) |

---

## recommended pipelines

from `briefs/recommended-pipelines.md`:

| # | pipeline | dens.Î” | dens.Ïƒ | kern.Î” | use case |
|---|----------|--------|--------|--------|----------|
| 1 | `sup:[kernelize], [[req-kernels, sitrep-aggressive], [telegraphic]]` | +5.1 | 1.9 | -0.3 | **default** |
| 2 | `sup:[kernelize], [[req-kernels, sitrep-aggressive], [req-kernels, sitrep-taskaware], [req-kernels, telegraphic]]` | +4.3 | 2.7 | 0.0 | lossless |
| 3 | `sup:[kernelize], [[sitrep-iterative], [telegraphic]]` | +3.8 | 3.3 | 0.0 | lossless (simple) |
| 4 | `sup:[kernelize], [[sitrep-iterative], [telegraphic], [telegraphic]]` | +5.0 | 7.1 | -0.5 | drafts |
| 5 | `sup:[kernelize], [[sitrep-aggressive], [telegraphic]], ver:[restore]` | +8.8 | 14.0 | -0.4 | max compression |

`--help` will show these as examples.

---

## evaluation

### pros

- **single command** â€” no separate kernelize + compress + compare
- **self-grading** â€” metrics inline, no manual validation
- **fail-fast** â€” catches ambiguous briefs before compression
- **variance measurement** â€” N attempts reveal stability
- **pipeline flexibility** â€” any combination of briefs

### cons

- **latency** â€” N attempts = NÃ— latency (default 3Ã—)
- **cost** â€” more brain calls = more tokens spent
- **complexity** â€” onPress spec syntax has a learn curve

### edge cases

| edge case | behavior |
|-----------|----------|
| empty brief | fail fast: "empty content" |
| brief with no kernels | fail fast: "no kernels extracted" |
| kernelization variance > threshold | fail fast: "kernelization unstable" |
| kernel loss with `--onVerify restore` | restore lost kernels from source |
| kernel loss without `--onVerify` | warn but proceed |

### pit of success

- default pipeline is the most stable (#1)
- `--onVerify restore` recovers any lost kernels
- unstable briefs are rejected before compression
- metrics are always shown â€” no hidden failures

---

## dependencies

| dependency | source | status |
|------------|--------|--------|
| kernelize | `skills/kernelize/` | available |
| brief.compress | `skills/brief.compress/` | available |
| extractKernels | `domain.operations/kernelize/` | available |
| checkKernelRetention | `domain.operations/kernelize/` | available |
| genContextBrain | `rhachet` | available |

the condense skill composes these available primitives â€” no new brain calls or algorithms required.

---

## success criteria

1. **single command** â€” `npx rhachet run --skill condense --from X` works
2. **self-grading** â€” output shows dens.Î”, dens.Ïƒ, kern.Î”, kern.Ïƒ
3. **fail-fast** â€” unstable briefs rejected before compression
4. **variance measurement** â€” N attempts with aggregated metrics
5. **pipeline flexibility** â€” custom `--onPress` spec accepted
6. **verification mode** â€” `--onVerify restore` works
7. **recommended pipelines** â€” `--help` shows top 5 from recommended-pipelines.md
