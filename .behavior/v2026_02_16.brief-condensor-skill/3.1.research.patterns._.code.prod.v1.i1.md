# research patterns: production codepath

## kernel extraction

### [REUSE] extractKernels

**location**: `src/domain.operations/kernelize/extractKernels.ts`

```ts
export const extractKernels = async (
  input: { content: string },
  context: { brain: Brain; log: LogMethods },
): Promise<KernelExtractionResult>
```

**what**: single-pass kernel extraction via brain with structured output schema

**pattern**:
- brain-driven extraction with forethought/rationale chain-of-thought
- returns `ConceptKernel[]` with id, concept, category, importance
- category enum: `rule`, `pattern`, `definition`, `constraint`, `example`, `reference`

**relevance**: condense needs kernel extraction before compression to measure retention

---

### [REUSE] extractKernelsWithConsensus

**location**: `src/domain.operations/kernelize/extractKernels.ts`

```ts
export const extractKernelsWithConsensus = async (
  input: { content: string; runs: number; threshold: number },
  context: { brain: Brain; log: LogMethods },
): Promise<{ kernels: ConsensusKernel[]; stability: ConsensusStability }>
```

**what**: N parallel extraction runs with jaccard stability measurement

**pattern**:
- runs N extractions in parallel
- clusters semantically similar kernels via `clusterKernels`
- computes pairwise jaccard similarity for stability
- returns `ConsensusStability`: meanJaccard, minJaccard, maxJaccard

**relevance**: condense uses this to detect unstable briefs (meanJaccard < 0.7 = fail fast)

---

### [REUSE] checkKernelRetention

**location**: `src/domain.operations/kernelize/extractKernels.ts`

```ts
export const checkKernelRetention = async (
  input: { kernels: ConceptKernel[]; content: string },
  context: { brain: Brain; log: LogMethods },
): Promise<{ retained: ConceptKernel[]; lost: ConceptKernel[]; retentionRate: number }>
```

**what**: verify which kernels survive in compressed content

**pattern**:
- brain-driven semantic match (not string search)
- returns retained/lost arrays and retention rate
- enables kern.Δ calculation

**relevance**: condense needs this to self-grade compression quality

---

### [REUSE] clusterKernels

**location**: `src/domain.operations/kernelize/extractKernels.ts`

```ts
export const clusterKernels = async (
  input: { kernels: ConceptKernel[] },
  context: { brain: Brain; log: LogMethods },
): Promise<ConceptKernelCluster[]>
```

**what**: brain-driven semantic cluster of kernels

**pattern**:
- groups semantically equivalent kernels (handles synonyms, rephrases)
- assigns cluster id and representative kernel
- enables stable comparison across extraction runs

**relevance**: consensus stability depends on this for jaccard calculation

---

## compression

### [EXTEND] compressViaBhrain

**location**: `src/domain.roles/mechanic/skills/brief.compress/compress.via.bhrain.ts`

```ts
export const compressViaBhrain = async (
  input: {
    content: string;
    mechanism: MechanismOrModifier[];
    kernels?: ConceptKernel[];
  },
  context: { brain: Brain; log: LogMethods; cacheDir?: string },
): Promise<{ compressed: string; tokens: { before: number; after: number } }>
```

**what**: brain-powered sitrep compression with methodology briefs

**pattern**:
- accepts `MechanismOrModifier[]` for pipeline composition
- mechanisms: `sitrep`, `telegraphic`, `sitrep-aggressive`, `sitrep-taskaware`, `sitrep-iterative`
- modifiers: `req-kernels` (injects kernels into prompt)
- on-disk cache with content hash invalidation

**extension needed**:
- current api takes flat array of mechanisms for single step
- condense needs multi-step pipeline: `[[step1-briefs], [step2-briefs], ...]`
- extend to accept `MechanismOrModifier[][]` or iterate externally

---

### [REUSE] genCompressionPrompt

**location**: `src/domain.roles/mechanic/skills/brief.compress/compress.via.bhrain.ts`

```ts
const genCompressionPrompt = (
  input: { content: string; mechanism: MechanismOrModifier[]; kernels?: ConceptKernel[] },
): string
```

**what**: generates compression prompt based on mechanism combination

**pattern**:
- loads methodology briefs from `briefs/` directory
- combines multiple briefs into single prompt
- injects kernels when `req-kernels` modifier present

**relevance**: condense reuses this for each pipeline step

---

### [REUSE] on-disk cache

**location**: `src/domain.roles/mechanic/skills/brief.compress/compress.via.bhrain.ts`

**pattern**:
```ts
const cacheKey = toHashSha256Sync([content, mechanism.join(',')].join('::'));
const cachePath = path.join(cacheDir, `${cacheKey}.json`);
```

- content hash + mechanism combination as cache key
- json file per cached result
- invalidates on content or mechanism change

**relevance**: condense can reuse for variance runs (same content, same pipeline = cache hit)

---

## skill cli

### [REUSE] turtle vibes output

**location**: `src/domain.roles/mechanic/skills/*/output.sh`

**pattern**:
```sh
print_turtle_header "shell yeah!"
print_tree_start "condense"
print_tree_branch "result"
print_tree_leaf "dens.Δ" "+5.1"
```

- consistent tree-structured output
- emoji headers for success/failure
- branch/leaf hierarchy for nested data

**relevance**: condense uses same output format for consistency

---

### [REUSE] rhachet arg handle

**location**: `src/domain.roles/mechanic/skills/kernelize/kernelize.ts`

**pattern**:
```ts
while (args.length > 0) {
  const arg = args.shift()!;
  switch (arg) {
    case '--skill': case '--repo': case '--role':
      args.shift(); // skip rhachet args
      break;
    case '--from':
      from = args.shift()!;
      break;
    // ...
  }
}
```

- ignore rhachet-injected args
- named args with validation
- fail fast on unknown args

**relevance**: condense skill follows same cli pattern

---

## domain types

### [REUSE] ConceptKernel

```ts
interface ConceptKernel {
  id: string;
  concept: string;
  category: 'rule' | 'pattern' | 'definition' | 'constraint' | 'example' | 'reference';
  importance: 'critical' | 'high' | 'medium' | 'low';
}
```

**relevance**: core type for kernel extraction and retention check

---

### [REUSE] ConsensusStability

```ts
interface ConsensusStability {
  meanJaccard: number;
  minJaccard: number;
  maxJaccard: number;
}
```

**relevance**: condense uses this for unstable brief detection (threshold: 0.7)

---

### [EXTEND] MechanismOrModifier

```ts
type Mechanism = 'sitrep' | 'telegraphic' | 'sitrep-aggressive' | 'sitrep-taskaware' | 'sitrep-iterative';
type Modifier = 'req-kernels';
type MechanismOrModifier = Mechanism | Modifier;
```

**extension needed**: add `kernelize` mechanism for supply step

---

## summary

| pattern | status | rationale |
|---------|--------|-----------|
| `extractKernels` | [REUSE] | kernel extraction for supply step |
| `extractKernelsWithConsensus` | [REUSE] | stability detection for fail-fast |
| `checkKernelRetention` | [REUSE] | kern.Δ calculation |
| `clusterKernels` | [REUSE] | consensus stability measurement |
| `compressViaBhrain` | [EXTEND] | needs multi-step pipeline support |
| `genCompressionPrompt` | [REUSE] | prompt generation per step |
| on-disk cache | [REUSE] | variance run optimization |
| turtle vibes output | [REUSE] | consistent cli output |
| rhachet arg handle | [REUSE] | standard skill cli pattern |
| `ConceptKernel` | [REUSE] | core domain type |
| `ConsensusStability` | [REUSE] | stability metrics |
| `MechanismOrModifier` | [EXTEND] | add `kernelize` for supply |

---

## architecture for condense

```
condense.ts
├── parseArgs()           → [REUSE] rhachet pattern
├── onSupply: kernelize   → [REUSE] extractKernelsWithConsensus
│   └── fail if unstable  → [REUSE] ConsensusStability threshold
├── onPress: pipeline     → [EXTEND] iterate compressViaBhrain per step
│   └── req-kernels       → [REUSE] kernel injection via modifier
├── onVerify: restore     → [NEW] append lost kernels to output
├── metrics               → [REUSE] checkKernelRetention for kern.Δ
└── output                → [REUSE] turtle vibes tree format
```

**new code needed**:
- `condense.ts` skill entry point
- `condense.sh` shell wrapper
- multi-step pipeline iteration
- `restore` verify operation (append lost kernels)
- variance aggregation (dens.σ, kern.σ)
