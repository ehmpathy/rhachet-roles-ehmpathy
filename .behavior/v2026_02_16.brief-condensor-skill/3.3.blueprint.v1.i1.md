# blueprint: condense skill

## overview

the condense skill is an atomic operation that compresses briefs while self-grade of quality via kernel retention measurement.

**pipeline**: `supply → press → verify`
- **supply**: extract kernels before compression (for measurement)
- **press**: apply compression steps (multi-step, multi-brief pipelines)
- **verify**: check kernel retention, optionally restore lost kernels

---

## treestruct of filediffs

```
src/domain.roles/mechanic/skills/
├── [+] condense/
│   ├── [+] condense.sh                           # shell entry point
│   ├── [+] condense.ts                           # main orchestrator
│   ├── [+] condense.integration.test.ts          # contract tests
│   ├── [+] condense.perfeval.integration.test.ts # variance measurement tests
│   ├── [+] output.sh                             # turtle vibes output helpers
│   │
│   ├── [+] domain.operations/
│   │   ├── [+] supply/
│   │   │   └── [+] assertStability.ts             # fail if meanJaccard < 0.7
│   │   │
│   │   ├── [+] press/
│   │   │   └── [+] pressViaPipeline.ts           # composes compressViaBhrain calls per step
│   │   │
│   │   └── [+] verify/
│   │       ├── [+] checkRetention.ts             # compare kernels before/after
│   │       └── [+] restoreKernels.ts             # recompress with lost kernels as required supplements (never mechanical append)
│   │
│   ├── [+] briefs/
│   │   └── [+] recommended-pipelines.md          # top 5 pipelines for --help
│   │
│   └── [+] .test/
│       └── [+] fixtures/
│           └── [+] briefs/                       # test brief fixtures
│               ├── [+] stable-rule.md            # stable brief for happy path
│               └── [+] unstable-ambiguous.md     # unstable brief for fail-fast test
│
├── brief.compress/
│   ├── [○] compress.via.bhrain.ts                # reuse as-is (call per step)
│   └── [○] extractKernels.ts                     # reuse as-is
│
└── kernelize/
    ├── [○] extractKernels.ts                     # reuse for kernel extraction
    ├── [○] extractKernelsWithConsensus.ts        # reuse for stability check
    ├── [○] clusterKernels.ts                     # reuse for semantic group
    └── [○] checkKernelRetention.ts               # reuse for retention check
```

**legend**:
- `[+]` = create new
- `[~]` = update/extend
- `[○]` = reuse as-is
- `[←]` = re-export from other location

---

## treestruct of codepaths

```
condense.sh
├── parse args (--from, --into, --onSupply, --onPress, --onVerify, --attempts, --mode, --brain)
├── validate args
│   ├── --from must resolve to ≥1 file
│   ├── --onPress must parse as valid JSON array
│   └── --onSupply/--onVerify must be known operations
└── invoke condense.ts

condense.ts
├── [+] parseArgs()                               # rhachet arg handle pattern
├── [+] validatePipelineSpec()                    # parse and validate --onPress
├── [+] condenseFile()                            # per-file orchestration
│   │
│   ├── kernelize (always, for measurement)
│   │   ├── [○] extractKernelsWithConsensus()     # reuse from skills/kernelize/
│   │   ├── [+] assertStability()                  # fail-fast if meanJaccard < 0.7
│   │   └── return { kernels, stability }
│   │
│   ├── onPress: pipeline (N attempts)
│   │   ├── [+] runAttempts()                     # parallel N runs
│   │   │   └── [+] pressViaPipeline()            # domain.operations/press/
│   │   │       └── [○] compressViaBhrain()       # inject kernels if onSupply=kernelize
│   │   ├── [+] aggregateMetrics()                # compute mean, σ
│   │   └── return { compressed, tokens, metrics[] }
│   │
│   ├── verify retention (always, for measurement)
│   │   ├── [+] checkRetention()                  # domain.operations/verify/
│   │   │   └── [○] checkKernelRetention()        # reuse from skills/kernelize/
│   │   ├── [+] restoreKernels()                  # only if onVerify=restore
│   │   │   └── [○] compressViaBhrain()           # recompress with lost kernels as supplements
│   │   └── return { retained, lost, retentionRate }
│   │
│   └── [+] computeFinalMetrics()                 # dens.Δ, dens.σ, kern.Δ, kern.σ
│
├── [+] emitOutput()                              # turtle vibes tree format
└── return exit code

output.sh
├── [○] print_turtle_header()                     # reuse from brief.compress
├── [○] print_tree_start()                        # reuse from brief.compress
├── [○] print_tree_branch()                       # reuse from brief.compress
└── [○] print_tree_leaf()                         # reuse from brief.compress
```

---

## inline output types

output types are declared inline on the procedures that produce them (per `rule.forbid.io-as-domain-objects`).

### condense output (inline on condense.ts)

```ts
export const condense = async (
  input: { from: string; into?: string; ... },
  context: { brain: Brain; log: LogMethods },
): Promise<{
  from: string;
  into: string;
  compressed: string;
  pipeline: {
    supply: 'kernelize' | null;           // null = kernels extracted but not injected
    press: PressBrief[][];                 // step array
    verify: 'restore' | null;
  };
  tokens: { before: number; after: number };
  kernels: { before: number; after: number; delta: number };
  density: { before: number; after: number; delta: number };
  stability: { meanJaccard: number; minJaccard: number; maxJaccard: number };
  variance: { densityσ: number; kernelσ: number } | null;
  attempts: number;
}> => { ... };
```

### pressViaPipeline output (inline)

```ts
export const pressViaPipeline = async (
  input: { content: string; pipeline: PressBrief[][]; kernels?: ConceptKernel[] },
  context: { brain: Brain; log: LogMethods },
): Promise<{
  content: string;
  tokens: { before: number; after: number };
}> => { ... };
```

### checkRetention output (inline)

```ts
export const checkRetention = async (
  input: { kernels: ConceptKernel[]; content: string },
  context: { brain: Brain; log: LogMethods },
): Promise<{
  retained: ConceptKernel[];
  lost: ConceptKernel[];
  retentionRate: number;
}> => { ... };
```

---

## test coverage

### unit tests

| file | coverage |
|------|----------|
| `validatePipelineSpec.test.ts` | parse valid/invalid --onPress specs |
| `assertStability.test.ts` | meanJaccard threshold logic |
| `aggregateMetrics.test.ts` | mean and σ computation |
| `computeFinalMetrics.test.ts` | dens.Δ, kern.Δ calculation |
| `restoreKernels.test.ts` | recompress with lost kernels as required supplements |

### integration tests

| file | coverage |
|------|----------|
| `condense.integration.test.ts` | end-to-end contract tests |
| `pressViaPipeline.integration.test.ts` | multi-step compression |
| `checkRetention.integration.test.ts` | kernel comparison via brain |
| `condense.perfeval.integration.test.ts` | variance measurement |

### acceptance tests

| file | coverage |
|------|----------|
| `condense.acceptance.test.ts` | blackbox cli behavior |

---

## integration test cases

from `2.1.criteria.blackbox.md`:

```ts
describe('condense', () => {
  // shared setup
  const dbConnection = useBeforeAll(() => getDatabaseConnection());
  afterAll(async () => dbConnection.end());

  given('[case1] valid markdown brief', () => {
    const scene = useBeforeAll(async () => {
      const brief = await loadTestBrief('stable-rule');
      return { brief };
    });

    when('[t0] condense with default pipeline', () => {
      const result = useThen('it succeeds', async () =>
        runCondense({ from: scene.briefPath }),
      );

      then('output shows pipeline used', () => {
        expect(result.stdout).toContain('sup:[kernelize]');
        expect(result.stdout).toContain('req-kernels, sitrep-aggressive');
      });

      then('output shows dens.Δ metric', () => {
        expect(result.stdout).toMatch(/dens\.Δ: [+-]?\d+\.\d+/);
      });

      then('output shows kern.Δ metric', () => {
        expect(result.stdout).toMatch(/kern\.Δ: [+-]?\d+\.\d+/);
      });

      then('exit code is 0', () => {
        expect(result.exitCode).toEqual(0);
      });
    });

    when('[t1] condense with --mode plan', () => {
      const result = useThen('it succeeds', async () =>
        runCondense({ from: scene.briefPath, mode: 'plan' }),
      );

      then('no .min file is created', async () => {
        const minPath = `${scene.briefPath}.min`;
        expect(await fileExists(minPath)).toEqual(false);
      });
    });

    when('[t2] condense with --mode apply', () => {
      const result = useThen('it succeeds', async () =>
        runCondense({ from: scene.briefPath, mode: 'apply' }),
      );

      then('.min file is created', async () => {
        const minPath = `${scene.briefPath}.min`;
        expect(await fileExists(minPath)).toEqual(true);
      });

      then('source file is unchanged', async () => {
        const content = await fs.readFile(scene.briefPath, 'utf-8');
        expect(content).toEqual(scene.brief);
      });
    });
  });

  given('[case2] unstable brief', () => {
    const scene = useBeforeAll(async () => {
      const brief = await loadTestBrief('unstable-ambiguous');
      return { brief };
    });

    when('[t0] condense is invoked', () => {
      const result = useThen('it fails', async () =>
        runCondense({ from: scene.briefPath }),
      );

      then('output shows kernelization unstable error', () => {
        expect(result.stdout).toContain('kernelization unstable');
      });

      then('output shows stability.meanJaccard < 0.7', () => {
        expect(result.stdout).toMatch(/stability\.meanJaccard: 0\.[0-6]/);
      });

      then('exit code is 2', () => {
        expect(result.exitCode).toEqual(2);
      });
    });
  });

  given('[case3] brief with kernel loss', () => {
    when('[t0] condense without --onVerify', () => {
      then('output shows warn about kernel loss');
      then('compression proceeds');
      then('exit code is 0');
    });

    when('[t1] condense with --onVerify restore', () => {
      then('lost kernels are appended to output');
      then('kern.Δ after restore is 0 or positive');
    });
  });

  given('[case4] empty brief', () => {
    when('[t0] condense is invoked', () => {
      then('output shows error: "empty content"');
      then('exit code is 1');
    });
  });

  given('[case5] invalid pipeline spec', () => {
    when('[t0] malformed --onPress', () => {
      then('output shows syntax error');
      then('exit code is 1');
    });

    when('[t1] unknown brief name in --onPress', () => {
      then('output shows error: "unknown brief: {name}"');
      then('exit code is 1');
    });
  });

  given('[case6] batch glob', () => {
    when('[t0] condense with glob pattern', () => {
      then('each file matched is processed');
      then('each file gets its own .min output');
    });
  });
});
```

---

## implementation order

### phase 1: supply operations

in `skills/condense/domain.operations/supply/`:

1. `assertStability.ts` — fail if meanJaccard < 0.7 (uses `extractKernelsWithConsensus` from kernelize)

### phase 2: press operations

in `skills/condense/domain.operations/press/`:

1. `pressViaPipeline.ts` — multi-step compression orchestrator (uses `compressViaBhrain` from brief.compress)

### phase 3: verify operations

in `skills/condense/domain.operations/verify/`:

1. `checkRetention.ts` — wrapper for `checkKernelRetention` from kernelize
2. `restoreKernels.ts` — recompress with lost kernels as required supplements (never mechanical append)

### phase 4: main orchestrator

in `skills/condense/`:

1. `condense.ts` — main logic
2. `condense.sh` — shell entry point
3. `output.sh` — turtle vibes helpers

### phase 5: tests

1. unit tests for pure logic (domain.operations)
2. integration tests for brain calls
3. acceptance tests for cli behavior

---

## reuse summary

| component | status | source |
|-----------|--------|--------|
| `extractKernels` | reuse | `skills/kernelize/` |
| `extractKernelsWithConsensus` | reuse | `skills/kernelize/` |
| `clusterKernels` | reuse | `skills/kernelize/` |
| `checkKernelRetention` | reuse | `skills/kernelize/` |
| `compressViaBhrain` | extend | `skills/brief.compress/` |
| `genCompressionPrompt` | reuse | `skills/brief.compress/` |
| `on-disk cache` | reuse | `skills/brief.compress/` |
| `turtle vibes output` | reuse | `skills/brief.compress/` |
| `rhachet arg handle` | reuse | standard pattern |
| `sanitizeOutput` | reuse | `skills/brief.compress/` |
| `genTempDir` | reuse | test utils |
| `useThen` | reuse | `test-fns` |
| `Bottleneck` | reuse | rate limiter |

---

## new code summary

| component | location | purpose |
|-----------|----------|---------|
| `condense.sh` | `skills/condense/` | shell wrapper |
| `condense.ts` | `skills/condense/` | orchestrates supply → press → verify |
| `assertStability.ts` | `skills/condense/domain.operations/supply/` | fail if unstable |
| `pressViaPipeline.ts` | `skills/condense/domain.operations/press/` | composes compressViaBhrain calls |
| `checkRetention.ts` | `skills/condense/domain.operations/verify/` | compare kernels |
| `restoreKernels.ts` | `skills/condense/domain.operations/verify/` | recompress with lost kernels as required supplements |
| `recommended-pipelines.md` | `skills/condense/briefs/` | top 5 pipelines for --help |

---

## dependencies

all dependencies are available in the codebase:

| dependency | source | status |
|------------|--------|--------|
| `extractKernels` | `skills/kernelize/` | ✓ available |
| `extractKernelsWithConsensus` | `skills/kernelize/` | ✓ available |
| `checkKernelRetention` | `skills/kernelize/` | ✓ available |
| `clusterKernels` | `skills/kernelize/` | ✓ available |
| `compressViaBhrain` | `skills/brief.compress/` | ✓ available |
| `genContextBrain` | `rhachet` | ✓ available |
| `ConsensusStability` | `skills/kernelize/` | ✓ available |
| `ConceptKernel` | `skills/kernelize/` | ✓ available |
| `PressBrief` | `skills/brief.compress/` | ✓ available |

---

## success metrics

from the vision document:

1. **single command** — `npx rhachet run --skill condense --from X` works
2. **self-grade** — output shows dens.Δ, dens.σ, kern.Δ, kern.σ
3. **fail-fast** — unstable briefs rejected before compression
4. **variance measurement** — N attempts with aggregated metrics
5. **pipeline flexibility** — custom `--onPress` spec accepted
6. **verification mode** — `--onVerify restore` works
7. **recommended pipelines** — `--help` shows top 5

