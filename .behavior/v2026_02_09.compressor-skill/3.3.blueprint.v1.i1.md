# blueprint: brief.compress skill

**date**: 2026-02-09
**scope**: implementation plan for the brief.compress skill

---

## executive summary

the brief.compress skill is a shell skill that invokes a typescript compression engine via bun. the skill follows the repo's shell skill patterns (header, arg parse, plan/apply modes, turtle output) while the compression logic is delegated to typescript code that uses `@atjsh/llmlingua-2`.

---

## architecture overview

```
rhx brief.compress path/to/brief.md
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ brief.compress.sh (shell skill)     â”‚
â”‚ - arg parse (path, --glob, --mode)  â”‚
â”‚ - validation (file exists, is .md)  â”‚
â”‚ - file enumeration (glob patterns)  â”‚
â”‚ - invokes bun for each file         â”‚
â”‚ - turtle output format              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ compress.ts (typescript engine)     â”‚
â”‚ - load @atjsh/llmlingua-2           â”‚
â”‚ - load model (TinyBERT/MobileBERT)  â”‚
â”‚ - compress text via token classify  â”‚
â”‚ - return compressed text + stats    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ brief.md.min (output file)          â”‚
â”‚ - collocated with source            â”‚
â”‚ - compressed markdown content       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## filediff treestruct

```
src/domain.roles/mechanic/skills/
â”œâ”€â”€ [+] brief.compress/
â”‚   â”œâ”€â”€ [+] brief.compress.sh                    # shell skill entrypoint
â”‚   â”œâ”€â”€ [+] compress.ts                          # typescript compression engine
â”‚   â”œâ”€â”€ [+] output.sh                            # turtle output helpers (source from git.commit)
â”‚   â”œâ”€â”€ [+] brief.compress.integration.test.ts   # integration tests
â”‚   â””â”€â”€ [+] __snapshots__/                       # snapshot directory
â”‚       â””â”€â”€ [+] brief.compress.integration.test.ts.snap
â”œâ”€â”€ [â—‹] git.commit/
â”‚   â””â”€â”€ [â—‹] output.sh                            # source for turtle output (reuse via copy)
â””â”€â”€ [â—‹] claude.tools/
    â””â”€â”€ [â—‹] sedreplace.sh                        # reference for arg parse pattern

package.json
â””â”€â”€ [~] dependencies                              # add @atjsh/llmlingua-2
```

**legend:**
- `[+]` create â€” file to create
- `[~]` update â€” file to update
- `[â—‹]` retain â€” file to retain (reference)

---

## codepath treestruct

```
brief.compress.sh
â”œâ”€â”€ [+] header block
â”‚   â”œâ”€â”€ [â†] .what/.why/.usage/.guarantee pattern (from sedreplace.sh)
â”‚   â””â”€â”€ [+] brief.compress-specific documentation
â”‚
â”œâ”€â”€ [+] arg parse
â”‚   â”œâ”€â”€ [â†] named arg parse pattern (from sedreplace.sh)
â”‚   â”œâ”€â”€ [+] --path / positional path handler
â”‚   â”œâ”€â”€ [+] --glob pattern handler
â”‚   â”œâ”€â”€ [+] --mode plan|apply handler
â”‚   â”œâ”€â”€ [+] --mech model selection (tinybert|mobilebert|bert|xlm-roberta)
â”‚   â”œâ”€â”€ [+] --ratio target compression ratio
â”‚   â”œâ”€â”€ [+] --force skip mtime check
â”‚   â”œâ”€â”€ [+] --validate behavioral equivalence check
â”‚   â””â”€â”€ [â†] rhachet passthrough (--repo, --role, --skill, --)
â”‚
â”œâ”€â”€ [+] validation
â”‚   â”œâ”€â”€ [â†] git repo check (from sedreplace.sh)
â”‚   â”œâ”€â”€ [+] file/glob provided check
â”‚   â”œâ”€â”€ [+] file exists check
â”‚   â”œâ”€â”€ [+] is markdown check (.md extension)
â”‚   â””â”€â”€ [+] model availability check (via compress.ts --check)
â”‚
â”œâ”€â”€ [+] file enumeration
â”‚   â”œâ”€â”€ [+] single file path handler
â”‚   â”œâ”€â”€ [+] glob pattern expansion via find
â”‚   â””â”€â”€ [+] no matches handler (exit 0 with message)
â”‚
â”œâ”€â”€ [+] compression loop
â”‚   â”œâ”€â”€ [+] for each file
â”‚   â”‚   â”œâ”€â”€ [+] mtime staleness check (skip if fresh)
â”‚   â”‚   â”œâ”€â”€ [+] invoke bun ./compress.ts
â”‚   â”‚   â”œâ”€â”€ [+] capture stats (tokens before/after, ratio)
â”‚   â”‚   â”œâ”€â”€ [+] write .md.min file (if apply mode)
â”‚   â”‚   â””â”€â”€ [+] aggregate stats
â”‚   â””â”€â”€ [+] validate flag handler (if enabled)
â”‚
â””â”€â”€ [+] output
    â”œâ”€â”€ [â†] turtle header pattern (from output.sh)
    â”œâ”€â”€ [â†] tree format pattern (from output.sh)
    â”œâ”€â”€ [+] compression stats in tree
    â”œâ”€â”€ [+] plan mode message
    â””â”€â”€ [+] error tree format (from output.sh)

compress.ts
â”œâ”€â”€ [+] cli interface
â”‚   â”œâ”€â”€ [+] --input file path
â”‚   â”œâ”€â”€ [+] --output file path (optional, for stats only)
â”‚   â”œâ”€â”€ [+] --model model name
â”‚   â”œâ”€â”€ [+] --rate compression ratio
â”‚   â”œâ”€â”€ [+] --check model availability check
â”‚   â””â”€â”€ [+] --json output format for shell consumption
â”‚
â”œâ”€â”€ [+] model load
â”‚   â”œâ”€â”€ [+] LLMLingua2.createCompressor({ model })
â”‚   â”œâ”€â”€ [+] model cache handler (auto via @huggingface/transformers)
â”‚   â””â”€â”€ [+] first-run download message
â”‚
â”œâ”€â”€ [+] compression
â”‚   â”œâ”€â”€ [+] read input file
â”‚   â”œâ”€â”€ [+] compressor.compress(content, { rate, force_tokens })
â”‚   â”œâ”€â”€ [+] force_tokens: ['\n', '.', '!', '?', ',', '```', '#']
â”‚   â””â”€â”€ [+] extract compressed text
â”‚
â”œâ”€â”€ [+] stats calculation
â”‚   â”œâ”€â”€ [+] tokens before (via js-tiktoken)
â”‚   â”œâ”€â”€ [+] tokens after
â”‚   â””â”€â”€ [+] compression ratio
â”‚
â””â”€â”€ [+] output
    â”œâ”€â”€ [+] write compressed content to --output (if provided)
    â””â”€â”€ [+] emit json stats to stdout

brief.compress.integration.test.ts
â”œâ”€â”€ [â†] bdd structure (given/when/then from test-fns)
â”œâ”€â”€ [â†] genTempDir for isolated git repos
â”œâ”€â”€ [â†] spawnSync for skill execution
â”œâ”€â”€ [â†] sanitizeOutput for stable snapshots
â”‚
â”œâ”€â”€ [+] given '[case1] single markdown brief'
â”‚   â”œâ”€â”€ [+] when '[t0] run with --mode plan'
â”‚   â”‚   â”œâ”€â”€ [+] then 'shows compression preview'
â”‚   â”‚   â”œâ”€â”€ [+] then 'shows token counts'
â”‚   â”‚   â”œâ”€â”€ [+] then 'does not create .md.min file'
â”‚   â”‚   â””â”€â”€ [+] then 'exits with code 0'
â”‚   â”‚
â”‚   â””â”€â”€ [+] when '[t1] run with --mode apply'
â”‚       â”œâ”€â”€ [+] then 'creates .md.min file'
â”‚       â”œâ”€â”€ [+] then 'compressed file is smaller'
â”‚       â”œâ”€â”€ [+] then 'reports compression ratio'
â”‚       â””â”€â”€ [+] then 'source file unchanged'
â”‚
â”œâ”€â”€ [+] given '[case2] glob pattern'
â”‚   â”œâ”€â”€ [+] when '[t0] matches multiple files'
â”‚   â”‚   â””â”€â”€ [+] then 'compresses all matched files'
â”‚   â””â”€â”€ [+] when '[t1] matches no files'
â”‚       â””â”€â”€ [+] then 'reports no files matched'
â”‚
â”œâ”€â”€ [+] given '[case3] extant .md.min file'
â”‚   â”œâ”€â”€ [+] when '[t0] source older than .md.min'
â”‚   â”‚   â””â”€â”€ [+] then 'skips with up-to-date message'
â”‚   â”œâ”€â”€ [+] when '[t1] source newer than .md.min'
â”‚   â”‚   â””â”€â”€ [+] then 'recompresses file'
â”‚   â””â”€â”€ [+] when '[t2] --force flag'
â”‚       â””â”€â”€ [+] then 'recompresses regardless'
â”‚
â”œâ”€â”€ [+] given '[case4] error conditions'
â”‚   â”œâ”€â”€ [+] when '[t0] file not found'
â”‚   â”‚   â””â”€â”€ [+] then 'exits non-zero with error'
â”‚   â”œâ”€â”€ [+] when '[t1] not a markdown file'
â”‚   â”‚   â””â”€â”€ [+] then 'exits non-zero with error'
â”‚   â””â”€â”€ [+] when '[t2] model not available'
â”‚       â””â”€â”€ [+] then 'reports install instructions'
â”‚
â”œâ”€â”€ [+] given '[case5] output format'
â”‚   â””â”€â”€ [+] when '[t0] successful compression'
â”‚       â”œâ”€â”€ [+] then 'output matches snapshot'
â”‚       â””â”€â”€ [+] then 'contains turtle emoji'
â”‚
â””â”€â”€ [+] given '[case6] help output'
    â””â”€â”€ [+] when '[t0] --help flag'
        â””â”€â”€ [+] then 'shows usage and exits 0'
```

**legend:**
- `[+]` create â€” codepath to create
- `[â—‹]` retain â€” codepath to retain
- `[â†]` reuse â€” codepath to reuse from elsewhere

---

## contract: brief.compress.sh

### inputs

| input | type | required | default | description |
|-------|------|----------|---------|-------------|
| `path` | string | yes* | â€” | positional or `--path` file to compress |
| `--glob` | string | yes* | â€” | glob pattern for batch (*one of path or glob required) |
| `--mode` | enum | no | `apply` | `plan` (preview) or `apply` (emit) |
| `--mech` | string | no | `mobilebert` | model: tinybert, mobilebert, bert, xlm-roberta |
| `--ratio` | number | no | `4` | target compression ratio (1-20) |
| `--force` | flag | no | false | recompress even if up-to-date |
| `--validate` | flag | no | false | run behavioral equivalence check |
| `--help` | flag | no | false | show usage |

### outputs

| output | when | format |
|--------|------|--------|
| `.md.min` file | mode=apply, success | collocated with source |
| stdout | always | turtle tree format |
| stderr | on error | error message |
| exit code | always | 0=success, 1=error |

### stdout format

```
ğŸ¢ lets see...

ğŸš brief.compress
   â”œâ”€ mode: plan
   â”œâ”€ mech: llmlingua/v2/mobilebert
   â”œâ”€ input: path/to/brief.md
   â”œâ”€ ratio: 4x target
   â””â”€ result
      â”œâ”€ tokens.before: 1200
      â”œâ”€ tokens.after: 312
      â””â”€ ratio.actual: 3.8x

note: this was a plan. to apply, re-run with --mode apply
```

---

## contract: compress.ts

### cli interface

```bash
bun ./compress.ts \
  --input path/to/brief.md \
  --output path/to/brief.md.min \
  --model mobilebert \
  --rate 0.25

bun ./compress.ts --check  # verify model availability
```

### json output (stdout)

```json
{
  "tokensBefore": 1200,
  "tokensAfter": 312,
  "ratio": 3.85,
  "compressed": "# compressed content here..."
}
```

### error output (stderr + exit 1)

```json
{
  "error": "model not found",
  "message": "MobileBERT model not installed",
  "install": "npm install @atjsh/llmlingua-2"
}
```

---

## domain.objects

no formal domain objects needed for v1. compression is a pure transformation with no lifecycle state.

for future validation feature, may introduce:

```typescript
interface CompressionResult {
  tokensBefore: number;
  tokensAfter: number;
  ratio: number;
  compressed: string;
}

interface ValidationResult {
  pass: boolean;
  score: number;
  degradations: string[];
}
```

---

## domain.operations

### computeCompression

```typescript
/**
 * .what = compress markdown via LLMLingua-2 token classification
 * .why = remove redundant tokens while semantic intent is preserved
 */
const computeCompression = async (
  input: {
    content: string;
    model: 'tinybert' | 'mobilebert' | 'bert' | 'xlm-roberta';
    rate: number;
  },
): Promise<{
  compressed: string;
  tokensBefore: number;
  tokensAfter: number;
  ratio: number;
}> => {
  // load compressor
  const compressor = await LLMLingua2.createCompressor({ model: input.model });

  // compress with force_tokens to preserve structural elements
  const result = await compressor.compress(input.content, {
    rate: 1 / input.rate, // rate is 0-1 scale; 0.25 = 4x compression
    force_tokens: ['\n', '.', '!', '?', ',', '```', '#', '*', '-', '|'],
    chunk_end_tokens: ['.', '\n'],
    drop_consecutive: true,
  });

  // count tokens
  const tokensBefore = countTokens(input.content);
  const tokensAfter = countTokens(result.compressed_prompt);

  return {
    compressed: result.compressed_prompt,
    tokensBefore,
    tokensAfter,
    ratio: tokensBefore / tokensAfter,
  };
};
```

### countTokens

```typescript
/**
 * .what = count tokens in text via tiktoken
 * .why = provide accurate token metrics for compression stats
 */
const countTokens = (input: { text: string }): number => {
  const encoder = getEncoder('cl100k_base');
  return encoder.encode(input.text).length;
};
```

---

## dependencies

### npm packages to add

```json
{
  "dependencies": {
    "@atjsh/llmlingua-2": "^2.0.3"
  }
}
```

the package bundles its own dependencies:
- `@huggingface/transformers`
- `@tensorflow/tfjs`
- `js-tiktoken`

### model download

models auto-download on first use to `~/.cache/huggingface/`:

| model | size | first-run download |
|-------|------|-------------------|
| TinyBERT | 57 MB | ~10s on fast connection |
| MobileBERT | 99 MB | ~20s on fast connection |
| BERT | 710 MB | ~2min on fast connection |
| XLM-RoBERTa | 2.2 GB | ~5min on fast connection |

---

## test coverage

### unit tests

none required for v1 â€” shell skill delegates to typescript, integration tests cover both.

### integration tests

| case | scope | file |
|------|-------|------|
| single file plan mode | skill contract | brief.compress.integration.test.ts |
| single file apply mode | skill contract | brief.compress.integration.test.ts |
| glob batch | skill contract | brief.compress.integration.test.ts |
| mtime staleness | skip logic | brief.compress.integration.test.ts |
| error conditions | validation | brief.compress.integration.test.ts |
| output format | turtle tree | brief.compress.integration.test.ts |
| help flag | usability | brief.compress.integration.test.ts |
| rhachet passthrough | integration | brief.compress.integration.test.ts |

### acceptance tests

none for v1 â€” skill is internal tool, not public api.

---

## implementation phases

### phase.0: scaffold

- [ ] create skill directory structure
- [ ] copy output.sh from git.commit/
- [ ] create brief.compress.sh skeleton with header
- [ ] create compress.ts skeleton
- [ ] add npm dependency

### phase.1: core compression

- [ ] implement compress.ts with LLMLingua-2
- [ ] implement brief.compress.sh arg parse
- [ ] implement single file compression flow
- [ ] implement turtle output format
- [ ] test: single file plan mode
- [ ] test: single file apply mode

### phase.2: batch and staleness

- [ ] implement glob pattern expansion
- [ ] implement mtime staleness check
- [ ] implement --force flag
- [ ] test: glob batch compression
- [ ] test: staleness skip
- [ ] test: force recompress

### phase.3: polish

- [ ] implement --help flag
- [ ] implement error output
- [ ] implement model availability check
- [ ] test: error conditions
- [ ] test: help output
- [ ] snapshot tests for output format

### phase.4: validation (future)

- [ ] implement --validate flag
- [ ] implement behavioral equivalence check
- [ ] test: validation pass
- [ ] test: validation fail

---

## risks and mitigations

| risk | likelihood | impact | mitigation |
|------|------------|--------|------------|
| @atjsh/llmlingua-2 is experimental | medium | medium | fallback to python if js port lacks features |
| model download on first run | high | low | document in help output, show progress |
| cpu inference is slow | high | low | default to MobileBERT, document gpu option |
| compression degrades brief behavior | low | high | implement --validate, default conservative ratio |
| force_tokens list incomplete | medium | medium | include common markdown tokens, iterate based on results |

---

## out of scope for v1

- behavioral equivalence validation (--validate flag)
- ci integration (stale .md.min detection)
- sessionstart hook integration
- parallel compression
- custom force_tokens list

---

## success criteria

1. `rhx brief.compress path/to/brief.md` produces `.md.min` file
2. compression achieves 2-4x token reduction on typical briefs
3. all tests pass
4. output follows turtle tree format
5. skill integrates with rhachet permissions

---

ğŸ¢ blueprint complete â€” ready for phase.0 scaffold ğŸŒŠ
