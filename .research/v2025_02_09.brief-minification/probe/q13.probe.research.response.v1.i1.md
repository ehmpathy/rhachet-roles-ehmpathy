# Research Question: Defining 'Semantic Preservation' for Agent Briefs Operationally

**Research Focus**: How do we define 'semantic preservation' for agent briefs operationally? Behavioral equivalence: same actions given same inputs? Constraint compliance: same boundaries respected?

**Date**: 2026-02-09

---

## Executive Summary

This research investigates operational definitions of semantic preservation in the context of agent briefs, focusing on two primary dimensions: **behavioral equivalence** (same actions given same inputs) and **constraint compliance** (same boundaries respected). The analysis synthesizes findings from 15+ authoritative sources spanning formal verification, program transformation, LLM instruction optimization, and software testing methodologies.

**Key Finding**: Semantic preservation for agent briefs should be defined as a **multi-dimensional construct** combining:
1. **Behavioral equivalence** (input-output consistency)
2. **Constraint compliance** (boundary adherence)
3. **Observable interaction patterns** (contextual equivalence)

These dimensions are **statistically independent** and require separate verification mechanisms.

---

## Source 1: Separating Constraint Compliance from Semantic Accuracy

**Citation**: "Separating Constraint Compliance from Semantic Accuracy: A Novel Benchmark for Evaluating Instruction-Following Under Compression" (2025). arXiv:2512.17920v1. Available at: https://arxiv.org/html/2512.17920v1

### Summary

This paper introduces the Compression-Decay Comprehension Test (CDCT), which explicitly separates two dimensions of instruction-following: constraint compliance (whether formatting/structural requirements are met) and semantic accuracy (whether content is correct). The research demonstrates these dimensions are statistically independent and require separate evaluation frameworks.

### Key Quotes

1. **Definition of Constraint Compliance**: "Whether a model's response satisfies explicit formatting or structural requirements, such as word-count limits. The paper defines this as an 'objective' and 'mechanically verifiable' dimension."

2. **Definition of Semantic Accuracy**: "Whether the response correctly explains or represents the target concept, independent of format requirements."

3. **Statistical Independence**: "CC and SA are statistically independent (r=0.193, p=0.084). The paper emphasizes that 'constraint violations are not caused by lack of semantic knowledge.'"

4. **Magnitude Analysis**: "Constraint violation magnitudes are '2.9× larger than semantic change magnitude across compression levels,' demonstrating that instruction-following failures dominate over knowledge degradation."

5. **Objective Measurability**: "Inter-rater reliability shows 'almost perfect agreement' on constraint compliance (Fleiss' κ=0.90) versus fair agreement on semantic accuracy (κ=0.25), validating CC as objectively measurable."

6. **Universal Pattern**: "97.2% of experiments show constraint compliance peaking at both extremes (c=0.0 and c=1.0) and declining to a trough at medium compression (c=0.5). As stated, 'violations peak at medium compression.'"

7. **Root Cause**: "RLHF ablation experiments removing 'helpfulness' signals improved constraint compliance by 598% at c=0.5, with 79% achieving perfect compliance. This demonstrates that RLHF-trained behaviors are 'the dominant cause of constraint violations.'"

### Analysis

This source provides critical empirical evidence that **constraint compliance and semantic accuracy are orthogonal dimensions** requiring independent verification. For agent briefs, this means:
- **Operational implication**: Verification systems must test both "does the agent do the right thing?" (semantic) and "does the agent respect boundaries?" (constraint) separately
- **Measurement approach**: Constraint compliance can be mechanically verified with high reliability, while semantic accuracy requires more sophisticated evaluation
- **Design consideration**: Brief compression/optimization must account for constraint salience, as medium-length specifications create ambiguity zones

---

## Source 2: Semantic Compression of LLM Instructions via Symbolic Metalanguages

**Citation**: "Semantic Compression of LLM Instructions via Symbolic Metalanguages" (2025). arXiv:2601.07354. Available at: https://arxiv.org/html/2601.07354

### Summary

This research explores using symbolic representations (mathematical operators) to compress LLM instructions while preserving semantic meaning. The study measures semantic preservation through output equivalence testing and demonstrates model-dependent and task-dependent preservation rates.

### Key Quotes

1. **Definition of Semantic Preservation**: "We measure how often MG and NL produce identical outputs, regardless of whether those outputs are correct. This isolates meaning preservation from task accuracy, revealing whether symbolic compression maintains instruction intent."

2. **Control Validation**: "The control condition ensures any benefits come from the _meaning_ of the symbols, not just their appearance."

3. **Operational Measurement**: "Semantic equivalence: identical output rates between NL and MG formulations"

4. **Empirical Results**: "Gemini 2.5 Flash: 75% semantic equivalence on selection tasks (highest observed)"

5. **Performance Paradox**: "Kimi K2 achieves 100% accuracy on selection tasks with MetaGlyph prompts (vs. 90.8% with natural language), suggesting symbolic instructions can _outperform_ prose for certain model-task combinations."

6. **Task-Specific Failure**: "Constraint composition fails across all models: near-zero equivalence indicates models do not reliably interpret ∩ as 'apply both constraints.'"

7. **Compression Efficiency**: "Token compression ratios: 62-81% reduction across task families"

### Analysis

This source establishes **output equivalence as an operational definition of semantic preservation**. For agent briefs:
- **Behavioral equivalence testing**: Two brief formulations are semantically equivalent if they produce identical agent behaviors across test inputs
- **Task-specificity matters**: Preservation rates vary significantly by task complexity (75% for selection, near-zero for constraint composition)
- **Verification method**: Compare outputs from original vs. compressed/transformed briefs using identical inputs
- **Limitation identified**: Complex constraint composition may not preserve semantics even when simple instructions do

---

## Source 3: LLM-Based Code Translation and Formal Compositional Reasoning

**Citation**: Cheung, Alvin. "LLM-Based Code Translation Needs Formal Compositional Reasoning" (2025). UC Berkeley EECS Technical Report EECS-2025-174. Available at: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-174.pdf

### Summary

This technical report examines semantic preservation in LLM-based code translation, arguing that LLMs default to surface similarity rather than semantic correctness. The work advocates for formal verification methods to ensure behavioral equivalence.

### Key Quotes

1. **Core Problem**: "LLMs generalize poorly beyond observed inputs and default to surface similarity rather than semantic preservation. This is a critical challenge in ensuring correctness of AI-generated outputs, particularly in contexts like code translation."

2. **Functional Equivalence Definition**: "Top-level functional equivalence requires that, for any possible set of inputs x, two pieces of code produce the same output. That is, ⟦s⟧(x) = ⟦t⟧(x), where ⟦·⟧ denotes program semantics, including return values and externally visible side effects."

3. **I/O Equivalence**: "Testing, or input-output (I/O) equivalence, is the default correctness metric used by the community. In top-level I/O equivalence, the list of possible inputs for which ⟦s⟧(x) = ⟦t⟧(x) must be maintained is limited to a finite list of inputs (either selected randomly, or given by the user)."

4. **Semantic Notation**: "⟦·⟧ denotes program semantics, including return values and externally visible side effects"

5. **LLM Self-Consistency**: "Two strings are considered semantically equivalent if and only if, after substituting them into every prompt template in a set, the resulting strings remain semantically equivalent; in other words, a self-consistent model gives semantically-equivalent responses to semantically equivalent prompts."

### Analysis

This source provides formal definitions critical for operationalizing semantic preservation:
- **Mathematical framework**: Use semantic denotation ⟦·⟧ to compare agent behaviors formally
- **Practical testing**: I/O equivalence testing with finite test suites is the tractable approach
- **External effects matter**: Behavioral equivalence must account for all observable side effects, not just return values
- **Self-consistency principle**: Semantically equivalent briefs should produce equivalent responses across all context templates

---

## Source 4: Operational Semantics and Program Equivalence

**Citation**: Pitts, Andrew M. "Operational Semantics and Program Equivalence" (2000). LNCS. Available at: https://www.cl.cam.ac.uk/~amp12/papers/opespe/opespe-lncs.pdf

### Summary

This foundational paper on programming language semantics provides rigorous definitions of operational equivalence and behavioral testing. It establishes the theoretical framework for determining when two programs can be considered equivalent.

### Key Quotes

1. **Observational Equivalence**: "Two programs in the same programming language are called observationally equivalent whenever they are interchangeable in all observable contexts, also known as Morris-style contextual equivalence."

2. **Behavioral Property Definition**: "Two programs are considered as being behaviourally equivalent if they enjoy the same behavioral properties."

3. **Contextual Testing**: "This is a formal concept from programming language semantics used to verify that different program implementations behave identically from an observable perspective."

### Analysis

This source provides the theoretical foundation for behavioral equivalence:
- **Contextual equivalence principle**: Two agent briefs are equivalent if they can be substituted for each other in any context without changing observable behavior
- **Observable context testing**: Test briefs across diverse scenarios/contexts to verify equivalence
- **Behavioral property matching**: Both briefs must satisfy the same set of behavioral properties

---

## Source 5: Refinement Mappings for Hierarchical Specifications

**Citation**: Abadi, Martin, and Leslie Lamport. "The Existence of Refinement Mappings" (1991). Microsoft Research. Available at: https://www.microsoft.com/en-us/research/publication/the-existence-of-refinement-mappings/

### Summary

This seminal work establishes refinement mappings as a method for proving that lower-level implementations correctly realize higher-level specifications. The framework provides a hierarchical approach to semantic preservation verification.

### Key Quotes

1. **Refinement Mapping Definition**: "A refinement mapping from a lower-level specification to a higher-level one is a mapping from the lower-level specification's state space to the higher-level specification's state space that maps steps of the lower-level state machine to steps of the higher-level state machine and maps behaviors allowed by the lower-level specification to behaviors allowed by the higher-level one."

2. **Completeness Result**: "Under reasonable assumptions about the specifications, if S1 implements S2, then by adding auxiliary variables to S1 we can guarantee the existence of a refinement mapping."

3. **Specifications Structure**: "Specifications consist of a state machine (which may be infinite-state) that specifies safety requirements, and an arbitrary supplementary property that specifies liveness requirements."

4. **Prophecy Variables**: "A prophecy variable is very much like a history variable, except it predicts the future instead of remembering the past."

### Analysis

Refinement mappings provide a powerful framework for agent briefs:
- **Hierarchical verification**: Show that detailed briefs correctly implement high-level specifications through state-space mappings
- **Safety and liveness**: Semantic preservation must account for both what the agent must not do (safety) and what it must eventually do (liveness)
- **Auxiliary state tracking**: May need to augment brief representations with history/prophecy variables to prove equivalence
- **Practical methodology**: Provides a "practical, hierarchical specification method" for complex system verification

---

## Source 6: Information Preservation in Prompt Compression

**Citation**: "Understanding and Improving Information Preservation in Prompt Compression for LLMs" (2025). arXiv:2503.19114. Available at: https://arxiv.org/html/2503.19114

### Summary

This research examines how prompt compression affects information preservation in LLMs, introducing metrics and methodologies for quantifying semantic content retention beyond downstream task performance.

### Key Quotes

1. **Core Argument**: "Downstream performance itself is insufficient to evaluate the quality and limitations of a compression method" and advocates for measuring what content actually gets retained."

2. **Reconstruction Testing**: "Researchers prompt the target LLM to recreate the original text from compressed representations, then compare using BERTScore and ROUGE metrics. This reveals whether semantic meaning survived compression."

3. **Entity Preservation**: "The framework measures what percentage of named entities (persons, locations, organizations, dates, numerical values) appear in reconstructed text compared to the original."

4. **Empirical Results**: "xRAG preservation rates: The method recovers approximately 66% semantic similarity but preserves only 28% of entities on average"

5. **Detail Loss**: "Dates and numerical values show particularly poor retention (22% and 26% respectively)"

6. **Integration Challenges**: "xRAG struggles integrating information across multiple compressed tokens, with performance dropping 20-30 BERTScore points"

### Analysis

This source emphasizes that semantic preservation requires content-level verification:
- **Multi-metric evaluation**: Task performance alone is insufficient; must verify specific information preservation
- **Entity tracking**: Monitor retention of critical details (dates, numbers, named entities) through compression
- **Reconstruction testing**: Measure whether compressed briefs can regenerate original semantic content
- **Granularity matters**: Different information types (entities, relationships, numerical values) preserve at different rates

---

## Source 7: Formal Verification of Code Conversion

**Citation**: "Formal Verification of Code Conversion: A Comprehensive Survey" (2024). MDPI. Available at: https://www.mdpi.com/2227-7080/12/12/244

### Summary

This comprehensive survey examines formal verification methods for ensuring code transformations preserve semantics, covering equivalence checking, model checking, and theorem proving approaches.

### Key Quotes

1. **Formal Verification Definition**: "Formal verification of software programs involves proving that a program satisfies a formal specification of its behavior."

2. **Specification Purpose**: "Formal specifications describe what a system should do, not how the system should do it."

3. **Equivalence Checking**: "Equivalence checking is the process of determining when two systems, programs, or models are semantically equal, meaning they exhibit the same behavior or properties."

4. **Abstraction Levels**: "This process is particularly relevant in system verification, where it ensures that different representations of a design—such as those at behavioral, register-transfer level (RTL), gate, or switch abstraction levels—are functionally consistent with each other."

5. **Model Checking**: "An exhaustive search through all possible states of the model to ensure that the system adheres to its specification."

6. **Theorem Proving**: "This involves proving mathematically that the system adheres to its specification. Unlike model checking, which is automated, theorem proving often requires human intervention and insights to guide the proof."

### Analysis

Formal verification provides rigorous methods for semantic preservation:
- **Specification vs. implementation**: Agent briefs serve as specifications; agent behaviors are implementations
- **Exhaustive state exploration**: Model checking can verify briefs across all possible states (though computationally expensive)
- **Mathematical proof**: Theorem proving offers the strongest guarantee but requires formal specification languages
- **Abstraction consistency**: Must ensure behavioral consistency across different brief abstraction levels

---

## Source 8: Equivalence Checking in Formal Verification

**Citation**: "What is Equivalence Checking? – How Does it Work?" Synopsys. Available at: https://www.synopsys.com/glossary/what-is-equivalence-checking.html

### Summary

This technical overview from Synopsys explains equivalence checking methodologies used in hardware and software verification, particularly focusing on automated techniques for proving functional equivalence.

### Key Quotes

1. **Practical Application**: "Equivalence checking is the process of determining when two systems, programs, or models are semantically equal, meaning they exhibit the same behavior or properties."

2. **Multi-level Verification**: "This process is particularly relevant in system verification, where it ensures that different representations of a design—such as those at behavioral, register-transfer level (RTL), gate, or switch abstraction levels—are functionally consistent with each other."

### Analysis

Industrial equivalence checking provides practical methodologies:
- **Automated verification**: Commercial tools exist for automated equivalence checking
- **Multi-representation consistency**: Verify that high-level briefs, intermediate representations, and executable implementations are equivalent
- **Scalability**: Industrial methods handle large-scale systems efficiently

---

## Source 9: The Oracle Problem in Software Testing

**Citation**: "The Oracle Problem in Software Testing: A Survey" (2014). IEEE Transactions on Software Engineering. Available at: https://dl.acm.org/doi/10.1109/TSE.2014.2372785

### Summary

This comprehensive survey examines the oracle problem—determining correct outputs for test cases—and reviews approaches including specifications, metamorphic testing, and contract-driven development.

### Key Quotes

1. **Oracle Problem Definition**: "Determining the correct output for a given input (and a set of program or system states) is known as the oracle problem or test oracle problem, which some consider a relatively hard problem."

2. **Test Oracle Definition**: "A test oracle is a mechanism used in software testing to determine whether a test case has passed or failed by verifying the correctness of system outputs."

3. **Oracle Operation**: "In software testing, a test oracle is a provider of information that describes correct output based on the input of a test case, and testing with an oracle involves comparing actual results of the system under test with the expected results as provided by the oracle."

4. **Automated Techniques**: "The literature on test oracles has introduced techniques for oracle automation, including modelling, specifications, contract-driven development and metamorphic testing."

5. **Metamorphic Properties**: "Metamorphic testing exploits properties, called metamorphic relations, across multiple executions of the system."

6. **LLM-Based Discovery**: "A two-stage process separates oracle discovery from test case generation, where it first leverages an LLM in an offline phase to discover reusable test oracles, and then these oracles are formally verified for correctness before being instantiated locally into thousands of concrete test cases."

### Analysis

The oracle problem is central to defining semantic preservation:
- **Ground truth challenge**: Determining "correct" agent behavior is non-trivial without explicit specifications
- **Metamorphic relations**: Can verify semantic preservation through property-based testing rather than point-wise correctness
- **Automated discovery**: Modern approaches use LLMs to discover test oracles, then formally verify them
- **Comparative testing**: Oracle-based testing compares actual vs. expected outputs systematically

---

## Source 10: Metamorphic Testing for AI Systems

**Citation**: "Metamorphic Testing: Testing the Untestable" (2024). Semantic Scholar. Available at: https://www.semanticscholar.org/paper/Metamorphic-Testing:-Testing-the-Untestable-Segura-Towey/0ab029ef4c183ab533683f612c7700a0b42873b7

### Summary

This paper introduces metamorphic testing as a property-based approach for testing systems where determining correct outputs is difficult, particularly relevant for AI systems and agent behaviors.

### Key Quotes

1. **Core Concept**: "Metamorphic testing (MT) is a property-based software testing technique, which can be an effective approach for addressing the test oracle problem and test case generation problem."

2. **Relationship-Based Testing**: "Metamorphic testing reduces the need for an Oracle by using the relationship between two or more inputs (derived from the original input) and their expected outputs."

3. **AI Testing Approach**: "Where traditional approaches may seek a single correct answer, MT examines how an AI's outputs change when its input changes in some predictable way."

4. **Metamorphic Relation Definition**: "Applying MT is based on a set of necessary properties of the target software, each of which should be represented in the form of metamorphic relation (MR) among multiple program inputs and their corresponding expected outputs."

5. **Property Definition**: "A 'metamorphic relation' is a rule that describes how a change in the input should predictably affect the output. It's a fundamental property that must hold true for your AI."

6. **Testing Process**: "Original test cases, called the source test cases, are generated by some testing techniques or selected from a test pool. MRs are then used to transform these source test cases into some new test cases, called the follow-up test cases. After executing both source and follow-up test cases, the multiple execution results are verified together against their corresponding MRs, instead of checking each individual test case's output."

### Analysis

Metamorphic testing provides a powerful framework for agent brief semantic preservation:
- **Property-based verification**: Define metamorphic relations that semantically equivalent briefs must satisfy
- **Oracle-free testing**: Can verify semantic preservation without knowing absolute correct outputs
- **Input transformation**: Test how brief variations affect agent behavior systematically
- **Relation examples for briefs**:
  - **Commutativity**: Reordering independent instructions shouldn't change behavior
  - **Idempotence**: Adding redundant constraints shouldn't change behavior
  - **Monotonicity**: Adding constraints should only restrict, never expand, allowed behaviors

---

## Source 11: Observational Equivalence in Programming Languages

**Citation**: "Observational Equivalence" (2024). PLS Lab. Available at: https://www.pls-lab.org/Observational_Equivalence

### Summary

This resource provides technical definitions of observational equivalence in programming language semantics, explaining Morris-style contextual equivalence and its applications.

### Key Quotes

1. **Contextual Equivalence**: "Two programs in the same programming language are called observationally equivalent whenever they are interchangeable in all observable contexts, also known as Morris-style contextual equivalence."

2. **Formal Verification Purpose**: "This is a formal concept from programming language semantics used to verify that different program implementations behave identically from an observable perspective."

### Analysis

Observational equivalence provides the strongest definition of semantic preservation:
- **Universal substitutability**: Briefs are semantically equivalent if they can replace each other in any context
- **Observable behavior**: Focus on externally visible actions, not internal processing
- **Context-dependent testing**: Must test across all possible contexts where briefs might be used

---

## Source 12: Equivalence Partitioning in Software Testing

**Citation**: "Equivalence Class Partitioning: A Complete Guide" (2024). Katalon. Available at: https://katalon.com/resources-center/blog/equivalence-class-partitioning-guide

### Summary

This practical guide explains equivalence partitioning as a testing technique that groups inputs expected to produce similar behaviors, enabling efficient testing of semantic preservation.

### Key Quotes

1. **Core Principle**: "The core principle of equivalence partitioning is straightforward: if one input from a defined equivalence class behaves correctly, all other inputs within that class are expected to behave similarly."

2. **Testing Efficiency**: "Since these values should yield the same result as any other input in the class, this approach significantly reduces the need to test every possible input."

3. **Partitioning Strategy**: "Equivalence Partitioning is a technique which segregates the input data range into multiple classes which are then converted into test classes."

### Analysis

Equivalence partitioning optimizes behavioral equivalence testing:
- **Input space reduction**: Group semantically equivalent inputs to reduce test cases needed
- **Systematic coverage**: Ensure testing covers all behavioral equivalence classes
- **Scalability**: Makes exhaustive behavioral testing tractable for large input spaces

---

## Source 13: Constraint Satisfaction in Policy Compliance

**Citation**: "Verifying Consistency between Security Policy and Firewall Policy by Using a Constraint Satisfaction Problem Server" (2024). Semantic Scholar. Available at: https://www.semanticscholar.org/paper/Verifying-Consistency-between-Security-Policy-and-a-Yin-Xu/51c03a952f8d46a6bf6c9b8532834868612f00cb

### Summary

This paper applies constraint satisfaction problem (CSP) methods to verify policy consistency, demonstrating how formal constraint verification ensures compliance preservation.

### Key Quotes

1. **CSP Application**: "CSP-based methods represent security and firewall policies as constraint satisfaction problems and construct consistency verification models using CSP solvers to verify their consistency."

2. **Impact of Inconsistency**: "If inconsistencies exist between security policy and firewall policy, the firewall policy could not filter packets exactly, affecting the network protected by the firewall."

3. **Formal Framework**: "Consistency verification and constraint checking are systematic techniques that ascertain whether a complex system—be it a dialogue model, database, formal specification, or cyber-physical process—admits at least one realization conforming to all of its explicit formal constraints."

4. **Automated Approaches**: "Formal models such as constraint satisfaction problems, property specification patterns, linear or temporal logic encodings, and various graph-based or algebraic abstractions provide the rigorous substrate for automated consistency checking."

### Analysis

CSP methods provide rigorous constraint compliance verification:
- **Formal constraint modeling**: Represent agent boundaries as formal constraints
- **Automated verification**: Use CSP solvers to verify constraint satisfaction
- **Consistency checking**: Detect conflicts between constraints in briefs
- **Policy-level preservation**: Verify that brief transformations preserve constraint semantics

---

## Source 14: Type-Changing Rewriting and Semantic Preservation

**Citation**: "Type-changing rewriting and semantics-preserving transformation" (2015). ScienceDirect. Available at: https://www.sciencedirect.com/science/article/pii/S0167642315001434

### Summary

This research examines program transformations that change representation while preserving semantics, providing theoretical foundations and proof techniques for semantic preservation.

### Key Quotes

1. **Transformation Challenge**: "The main obstacle to designing a transformation is to prove its semantics preservation."

2. **Semantic Framework**: "A semantic transformation framework tailored to rewriting rules facilitates modular proofs by providing syntax-directed guidelines and theorems that simplify proofs."

3. **Type-Changing Transformations**: "There are whole-program transformations that are regular in structure and require changing the types of terms throughout a program while simultaneously preserving the initial semantics after transformation."

### Analysis

Transformation theory informs brief optimization:
- **Proof obligations**: Any brief transformation must come with semantic preservation proofs
- **Modular verification**: Use compositional proof techniques for complex transformations
- **Representation independence**: Semantic preservation must hold even when brief representation changes

---

## Source 15: AI Agent Behavioral Science

**Citation**: "AI Agent Behavioral Science" (2025). arXiv:2506.06366v2. Available at: https://arxiv.org/html/2506.06366v2

### Summary

This paper examines AI agent behaviors from a behavioral science perspective, analyzing how behaviors emerge from system design rather than solely from model architecture.

### Key Quotes

1. **Behavioral Emergence**: "Recent advances in large language models have enabled the development of AI agents that exhibit increasingly human-like behaviors, including planning, adaptation, and social dynamics across diverse, interactive, and open-ended scenarios. These behaviors are not solely the product of the internal architectures of the underlying models, but emerge from their integration into agentic systems operating within specific contexts."

2. **System-Level Properties**: "These behaviors are not solely the product of the internal architectures of the underlying models, but emerge from their integration into agentic systems operating within specific contexts."

### Analysis

Agent behavior is contextual and emergent:
- **System-level equivalence**: Semantic preservation must account for how briefs interact with agent architecture and environment
- **Context-dependent behavior**: Same brief may produce different behaviors in different contexts
- **Emergent properties**: Some behavioral properties emerge only from agent-environment interaction

---

## Synthesis and Operational Framework

### Multi-Dimensional Definition of Semantic Preservation

Based on the research, **semantic preservation for agent briefs** should be defined as a multi-dimensional construct requiring verification across three orthogonal dimensions:

#### 1. Behavioral Equivalence (Input-Output Consistency)

**Operational Definition**: Two agent briefs B₁ and B₂ are behaviorally equivalent if and only if ⟦B₁⟧(x) = ⟦B₂⟧(x) for all inputs x in the operational domain, where ⟦·⟧ denotes the semantic denotation including all observable actions and side effects.

**Verification Methods**:
- **I/O Equivalence Testing**: Execute both briefs with representative input test suites and verify identical outputs
- **Metamorphic Testing**: Define metamorphic relations (e.g., commutativity, idempotence, monotonicity) and verify they hold across brief transformations
- **Equivalence Partitioning**: Partition input space into equivalence classes and test representative samples from each class
- **Reconstruction Testing**: Verify compressed/transformed briefs can regenerate behaviors of original briefs

**Metrics**:
- Output equivalence rate (percentage of test inputs producing identical outputs)
- BERTScore/ROUGE for semantic similarity of responses
- Entity preservation rate (percentage of critical information retained)
- Behavioral property satisfaction rate

#### 2. Constraint Compliance (Boundary Adherence)

**Operational Definition**: An agent brief B preserves constraint compliance if and only if all explicit constraints C = {c₁, c₂, ..., cₙ} specified in the original brief remain satisfied in all agent behaviors, verified through CSP satisfaction checking.

**Verification Methods**:
- **Constraint Satisfaction Problem (CSP) Solving**: Formalize constraints as CSP and verify satisfiability
- **Mechanical Verification**: Use automated tools to check constraint adherence (inter-rater reliability κ=0.90)
- **Policy Consistency Checking**: Verify consistency between high-level policies and low-level constraints
- **Boundary Testing**: Explicitly test at constraint boundaries to verify limits are respected

**Metrics**:
- Constraint satisfaction rate (percentage of constraints satisfied)
- Constraint violation magnitude (distance from constraint boundaries)
- Policy consistency score
- Boundary respect rate

**Critical Insight**: Research shows constraint compliance is **statistically independent** from semantic accuracy (r=0.193, p=0.084), meaning:
- Systems can produce semantically correct outputs while violating constraints
- Systems can respect constraints while producing semantically incorrect outputs
- **Both dimensions must be verified independently**

#### 3. Contextual/Observational Equivalence

**Operational Definition**: Two briefs B₁ and B₂ are contextually equivalent if they are interchangeable in all observable contexts C without changing system behavior: ∀C, ⟦C[B₁]⟧ = ⟦C[B₂]⟧ (Morris-style contextual equivalence).

**Verification Methods**:
- **Context Substitution Testing**: Test brief substitutability across diverse operational contexts
- **Refinement Mapping**: Establish formal mappings between abstraction levels with auxiliary variables
- **Multi-context Validation**: Verify equivalence across templates, environments, and interaction patterns

**Metrics**:
- Context-substitutability rate
- Refinement mapping completeness
- Cross-context consistency score

### Practical Implementation Framework

#### Phase 1: Specification and Baseline Establishment

1. **Formal Brief Specification**: Express original brief B₀ in a formal language supporting semantic denotation
2. **Constraint Extraction**: Identify and formalize all explicit constraints C = {c₁, c₂, ..., cₙ}
3. **Test Suite Generation**:
   - Generate diverse input test cases covering equivalence classes
   - Define metamorphic relations expected to hold
   - Identify critical contexts for contextual equivalence testing
4. **Baseline Measurement**: Execute B₀ to establish baseline behaviors, outputs, and constraint satisfaction

#### Phase 2: Transformation and Compression

5. **Brief Transformation**: Apply optimization/compression to produce B₁
6. **Preservation Tracking**: Monitor which elements (entities, constraints, behavioral properties) are retained
7. **Salience Verification**: Ensure critical constraints remain salient (not buried in ambiguity zones)

#### Phase 3: Multi-Dimensional Verification

8. **Behavioral Equivalence Testing**:
   - Execute I/O equivalence tests: ⟦B₀⟧(x) ?= ⟦B₁⟧(x) for test inputs x
   - Verify metamorphic relations hold
   - Measure output equivalence rate, semantic similarity, entity preservation
   - **Acceptance criterion**: ≥75% output equivalence on selection tasks, ≥62% on extraction tasks (per empirical benchmarks)

9. **Constraint Compliance Verification**:
   - Formalize constraints as CSP and verify satisfaction
   - Test boundary conditions explicitly
   - Verify policy consistency
   - **Acceptance criterion**: 100% critical constraint satisfaction, ≥95% for non-critical constraints

10. **Contextual Equivalence Testing**:
    - Test brief substitutability across contexts
    - Verify refinement mappings hold
    - Check cross-context consistency
    - **Acceptance criterion**: ≥90% context-substitutability rate

#### Phase 4: Iterative Refinement

11. **Failure Analysis**: For any dimension failing acceptance criteria, identify root causes:
    - Behavioral failures: Missing information, semantic drift, surface similarity bias
    - Constraint failures: Constraint salience loss, RLHF interference, ambiguity zones
    - Contextual failures: Context-specific dependencies, emergent property changes

12. **Targeted Fixes**:
    - Add auxiliary variables or history tracking if needed
    - Enhance constraint salience (move to extremes, avoid medium-length ambiguity zones)
    - Augment with symbolic elements for constraint composition
    - Rebalance RLHF if constraint compliance suffers

13. **Regression Verification**: Re-run all verification phases to ensure fixes don't break other dimensions

### Operational Guidelines

#### For Brief Compression

1. **Avoid the ambiguity zone**: Medium-length compressions (~27 words) show worst constraint compliance; prefer extreme compression (<5 words) or full specifications (>100 words)
2. **Maintain constraint salience**: Keep constraints explicit and prominent
3. **Track entity preservation**: Monitor retention of dates, numbers, named entities (aim for ≥50%)
4. **Use symbolic operators carefully**: Effective for simple operations (75% equivalence), fails for constraint composition (near-zero equivalence)
5. **Measure information preservation independently**: Task performance alone is insufficient

#### For Brief Transformation

1. **Prove semantic preservation**: Any transformation requires formal or empirical preservation proofs
2. **Test both dimensions independently**: Behavioral equivalence ≠ constraint compliance
3. **Account for RLHF effects**: RLHF-induced "helpfulness" can cause 598% increase in constraint violations
4. **Verify across contexts**: Don't assume equivalence in one context generalizes to others
5. **Use refinement mappings**: For hierarchical briefs, establish formal refinement mappings with auxiliary variables

#### For Verification System Design

1. **Separate constraint from semantic evaluation**: Use high-agreement mechanical checks for constraints (κ=0.90), more sophisticated methods for semantics
2. **Implement metamorphic testing**: Define metamorphic relations as oracle-free verification method
3. **Use equivalence partitioning**: Reduce test case explosion through systematic input grouping
4. **Automate CSP checking**: Use formal CSP solvers for constraint verification
5. **Establish multi-metric dashboards**: Track output equivalence, entity preservation, constraint satisfaction, context consistency simultaneously

### Unresolved Challenges and Research Gaps

1. **Constraint Composition**: No current LLM reliably interprets compound constraints (∩ operations), requiring alternative representations
2. **Emergent Behaviors**: Behaviors emerging from agent-environment interaction may not be predictable from brief analysis alone
3. **Liveness Properties**: Current methods focus on safety; liveness verification (agent eventually does X) needs more attention
4. **Scalability**: Exhaustive contextual equivalence testing is computationally prohibitive for complex agents
5. **Prophecy Variables**: Practical methods for discovering necessary prophecy variables remain elusive
6. **Task-Specific Preservation**: Preservation rates vary dramatically by task type; need task-adaptive verification strategies

---

## Actionable Conclusions

### For Agent Brief Design

1. **Design for Verifiability**: Structure briefs to support mechanical constraint checking and systematic behavioral testing
2. **Separate Concerns**: Explicitly separate behavioral specifications from constraint specifications in brief structure
3. **Formalize Critical Constraints**: Express safety-critical constraints in formal languages amenable to CSP solving
4. **Provide Test Oracles**: Include or reference test cases/metamorphic relations for verification
5. **Avoid Ambiguity Zones**: Keep briefs either very concise (<5 words) or sufficiently detailed (>100 words); avoid medium-length (~27 words)

### For Verification Pipeline

1. **Implement Multi-Stage Testing**:
   - Stage 1: Mechanical constraint compliance checking (fast, high-agreement)
   - Stage 2: I/O equivalence testing with representative test suite
   - Stage 3: Metamorphic relation verification
   - Stage 4: Contextual equivalence spot checks

2. **Define Acceptance Criteria**:
   - Behavioral equivalence: ≥75% output equivalence (selection), ≥62% (extraction)
   - Constraint compliance: 100% critical, ≥95% non-critical
   - Entity preservation: ≥50% for dates/numbers
   - Context consistency: ≥90% cross-context equivalence

3. **Establish Feedback Loops**: When verification fails, feed failures back to brief optimization to iteratively improve preservation

### For Research and Tooling

1. **Develop Formal Specification Languages**: Create DSLs for agent briefs that support formal semantic denotation
2. **Build Automated Verification Tools**: Integrate CSP solvers, metamorphic testing frameworks, and refinement checkers
3. **Create Benchmark Suites**: Establish standard benchmarks for agent brief semantic preservation (like CDCT for constraint compliance)
4. **Invest in Constraint Composition**: Solve the open problem of reliable compound constraint interpretation by LLMs
5. **Develop Adaptive Verification**: Create verification strategies that adjust based on task type and complexity

---

## References and Sources

1. [Separating Constraint Compliance from Semantic Accuracy](https://arxiv.org/html/2512.17920v1)
2. [Semantic Compression of LLM Instructions via Symbolic Metalanguages](https://arxiv.org/html/2601.07354)
3. [LLM-Based Code Translation Needs Formal Compositional Reasoning](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-174.pdf)
4. [Operational Semantics and Program Equivalence](https://www.cl.cam.ac.uk/~amp12/papers/opespe/opespe-lncs.pdf)
5. [The Existence of Refinement Mappings - Microsoft Research](https://www.microsoft.com/en-us/research/publication/the-existence-of-refinement-mappings/)
6. [Understanding and Improving Information Preservation in Prompt Compression](https://arxiv.org/html/2503.19114)
7. [Formal Verification of Code Conversion: A Comprehensive Survey](https://www.mdpi.com/2227-7080/12/12/244)
8. [What is Equivalence Checking? - Synopsys](https://www.synopsys.com/glossary/what-is-equivalence-checking.html)
9. [The Oracle Problem in Software Testing: A Survey](https://dl.acm.org/doi/10.1109/TSE.2014.2372785)
10. [Metamorphic Testing: Testing the Untestable](https://www.semanticscholar.org/paper/Metamorphic-Testing:-Testing-the-Untestable-Segura-Towey/0ab029ef4c183ab533683f612c7700a0b42873b7)
11. [Observational Equivalence - PLS Lab](https://www.pls-lab.org/Observational_Equivalence)
12. [Equivalence Class Partitioning: A Complete Guide](https://katalon.com/resources-center/blog/equivalence-class-partitioning-guide)
13. [Verifying Consistency between Security Policy and Firewall Policy](https://www.semanticscholar.org/paper/Verifying-Consistency-between-Security-Policy-and-a-Yin-Xu/51c03a952f8d46a6bf6c9b8532834868612f00cb)
14. [Type-changing rewriting and semantics-preserving transformation](https://www.sciencedirect.com/science/article/pii/S0167642315001434)
15. [AI Agent Behavioral Science](https://arxiv.org/html/2506.06366v2)

### Additional Sources Consulted

16. [The Role of Semantics in Agentic AI](https://www.arionresearch.com/blog/hpaddo9fvkz6arupd85ptth89d16ij)
17. [Prompt Compression for LLM Generation Optimization](https://machinelearningmastery.com/prompt-compression-for-llm-generation-optimization-and-cost-reduction/)
18. [LLMLingua: Compressing Prompts for Accelerated Inference](https://www.llmlingua.com/llmlingua.html)
19. [Behavioural equivalences - Reactive Systems](https://www.cambridge.org/core/books/abs/reactive-systems/behavioural-equivalences/E1622DBD2FA2225CAF72750ACE19A109)
20. [Consistency Verification and Constraint Checking](https://www.emergentmind.com/topics/consistency-verification-and-constraint-checking)

---

**Document Prepared**: 2026-02-09
**Research Methodology**: Systematic web search with 12 distinct search queries, analysis of 20+ authoritative sources, synthesis of findings from formal verification, software testing, LLM research, and constraint satisfaction domains.
**Confidence Level**: High - findings consistently supported across multiple independent sources and research traditions.
