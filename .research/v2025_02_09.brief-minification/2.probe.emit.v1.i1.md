# Probe Research Index: Telegraphic Semantic Compression

**Generated:** 2025-02-09
**Total Probes:** 35
**Total Research Size:** ~380 KB

---

## Domain 1: Foundational Linguistics & Semantics

| # | File | Question |
|---|------|----------|
| 1 | [q1.probe.research.response.v1.i1.md](probe/q1.probe.research.response.v1.i1.md) | Minimum Viable Semantic Unit (MVSU) for LLM Comprehension |
| 2 | [q2.probe.research.response.v1.i1.md](probe/q2.probe.research.response.v1.i1.md) | Function Words vs Content Words: Droppability for LLMs vs Humans |
| 3 | [q3.probe.research.response.v1.i1.md](probe/q3.probe.research.response.v1.i1.md) | Syntactic Structure in LLM Prompt Interpretation |
| 4 | [q4.probe.research.response.v1.i1.md](probe/q4.probe.research.response.v1.i1.md) | Telegraphic/Pidgin Language Compression Lessons |

---

## Domain 2: Information Theory & Redundancy

| # | File | Question |
|---|------|----------|
| 5 | [q5.probe.research.response.v1.i1.md](probe/q5.probe.research.response.v1.i1.md) | Shannon Entropy of Instruction Text vs Compressed Brief Text |
| 6 | [q6.probe.research.response.v1.i1.md](probe/q6.probe.research.response.v1.i1.md) | Zipf's Law, Information Content, and Token Importance |
| 7 | [q7.probe.research.response.v1.i1.md](probe/q7.probe.research.response.v1.i1.md) | Theoretical Compression Limits for Semantic-Preserving Text Reduction |
| 8 | [q8.probe.research.response.v1.i1.md](probe/q8.probe.research.response.v1.i1.md) | LLMs as Compressors vs Decompressors |

---

## Domain 3: Existing Tools & Techniques

| # | File | Question |
|---|------|----------|
| 9 | [q9.probe.research.response.v1.i1.md](probe/q9.probe.research.response.v1.i1.md) | LLMLingua Compression Ratios and Performance Cost |
| 10 | [q10.probe.research.response.v1.i1.md](probe/q10.probe.research.response.v1.i1.md) | LLMLingua vs TSC vs Summarization Comparison |
| 11 | [q11.probe.research.response.v1.i1.md](probe/q11.probe.research.response.v1.i1.md) | LLMLingua-2 Data Distillation vs Rule-Based Compression |
| 12 | [q12.probe.research.response.v1.i1.md](probe/q12.probe.research.response.v1.i1.md) | Prompt Compression Benchmarks and Instruction Compliance |

---

## Domain 4: Evaluation & Measurement

| # | File | Question |
|---|------|----------|
| 13 | [q13.probe.research.response.v1.i1.md](probe/q13.probe.research.response.v1.i1.md) | Defining "Semantic Preservation" for Agent Briefs |
| 14 | [q14.probe.research.response.v1.i1.md](probe/q14.probe.research.response.v1.i1.md) | Evaluation Methodologies for Detecting Subtle Knowledge Loss |
| 15 | [q15.probe.research.response.v1.i1.md](probe/q15.probe.research.response.v1.i1.md) | LLM-as-Judge for Compressed vs Uncompressed Behavior |
| 16 | [q16.probe.research.response.v1.i1.md](probe/q16.probe.research.response.v1.i1.md) | Acceptable Loss Thresholds for Brief Compression |

---

## Domain 5: Practical Application to Mechanic Briefs

| # | File | Question |
|---|------|----------|
| 17 | [q17.probe.research.response.v1.i1.md](probe/q17.probe.research.response.v1.i1.md) | Distinct Zones of Mechanic Briefs with Different Compression Tolerance |
| 18 | [q18.probe.research.response.v1.i1.md](probe/q18.probe.research.response.v1.i1.md) | Brief-Specific Tokens That Must NEVER Be Dropped |
| 19 | [q19.probe.research.response.v1.i1.md](probe/q19.probe.research.response.v1.i1.md) | Structured Formatting (JSON/YAML/Bullets) and Compression Strategy |
| 20 | [q20.probe.research.response.v1.i1.md](probe/q20.probe.research.response.v1.i1.md) | Domain-Specific Stop Word Lists for Brief Minification |
| 21 | [q21.probe.research.response.v1.i1.md](probe/q21.probe.research.response.v1.i1.md) | Multi-Language and Technical Jargon in Compression |

---

## Domain 6: Divergent Explorations

| # | File | Question |
|---|------|----------|
| 22 | [q22.probe.research.response.v1.i1.md](probe/q22.probe.research.response.v1.i1.md) | Small Compression LLM Preprocessing for Larger Inference Models |
| 23 | [q23.probe.research.response.v1.i1.md](probe/q23.probe.research.response.v1.i1.md) | Semantic Hashing and Embedding-Based Compression |
| 24 | [q24.probe.research.response.v1.i1.md](probe/q24.probe.research.response.v1.i1.md) | Custom Brief-Specific Compression Model Training |
| 25 | [q25.probe.research.response.v1.i1.md](probe/q25.probe.research.response.v1.i1.md) | Compression-Expansion: Adding Redundancy for Robustness |
| 26 | [q26.probe.research.response.v1.i1.md](probe/q26.probe.research.response.v1.i1.md) | Prompt Caching & KV-Cache Compression Interaction |

---

## Domain 7: Inversions & Failure Modes (Critical)

| # | File | Question |
|---|------|----------|
| 27 | [q27.probe.research.response.v1.i1.md](probe/q27.probe.research.response.v1.i1.md) | INVERSION: Compression Failures and Context Loss |
| 28 | [q28.probe.research.response.v1.i1.md](probe/q28.probe.research.response.v1.i1.md) | INVERSION: When is Verbosity Actually Necessary? |
| 29 | [q29.probe.research.response.v1.i1.md](probe/q29.probe.research.response.v1.i1.md) | INVERSION: Compression-Induced Ambiguity and Harm |
| 30 | [q30.probe.research.response.v1.i1.md](probe/q30.probe.research.response.v1.i1.md) | INVERSION: Adaptive vs One-Size-Fits-All Compression |
| 31 | [q31.probe.research.response.v1.i1.md](probe/q31.probe.research.response.v1.i1.md) | INVERSION: Training Data Bias and Concept Preservation |

---

## Domain 8: Real-World Evidence & Case Studies

| # | File | Question |
|---|------|----------|
| 32 | [q32.probe.research.response.v1.i1.md](probe/q32.probe.research.response.v1.i1.md) | Documented Production Uses of Prompt Compression |
| 33 | [q33.probe.research.response.v1.i1.md](probe/q33.probe.research.response.v1.i1.md) | TSC Applied to System Prompts / Role Instructions |
| 34 | [q34.probe.research.response.v1.i1.md](probe/q34.probe.research.response.v1.i1.md) | Compression Side Effects and Behavioral Drift |
| 35 | [q35.probe.research.response.v1.i1.md](probe/q35.probe.research.response.v1.i1.md) | A/B Testing Frameworks for Prompt Compression |

---

## Summary Statistics

| Domain | Probes | Focus |
|--------|--------|-------|
| Linguistics & Semantics | 4 | What can be dropped linguistically |
| Information Theory | 4 | Theoretical foundations of redundancy |
| Tools & Techniques | 4 | Existing compression solutions |
| Evaluation | 4 | Measuring compression quality |
| Practical Application | 5 | Brief-specific implementation |
| Divergent | 5 | Alternative approaches |
| Inversions | 5 | Failure modes and edge cases |
| Real-World Evidence | 4 | Production validation |

---

## Quick Reference: High-Priority Findings

### Critical for Safety
- **Q18**: Never-drop tokens (negations, quantifiers, constraints)
- **Q29**: Compression-induced ambiguity harm
- **Q27**: Compression failure case studies

### Highest Compression Potential
- **Q9**: LLMLingua 20x compression with 1.5% accuracy drop
- **Q10**: TSC vs LLMLingua method comparison
- **Q7**: Theoretical compression limits

### Implementation Guidance
- **Q17**: Brief zone compression tolerance
- **Q19**: Structured format compression
- **Q24**: Custom model training options

### Evaluation Framework
- **Q13**: Semantic preservation definition
- **Q14**: Knowledge loss detection
- **Q35**: A/B testing frameworks
