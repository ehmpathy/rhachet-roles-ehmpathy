# Research Question: Are Function Words vs Content Words Truly "Droppable" for LLMs vs Humans?

## Research Question (Expanded)

Which word classes are truly "droppable" for LLMs versus humans? Specifically, are function words (articles, conjunctions, prepositions) and content words (nouns, verbs, adjectives) processed differently by LLMs compared to human language parsing? Do LLMs rely on these word classes differently than humans do?

---

## Synthesis of Key Findings

### Function Words vs Content Words: Definition and Role

Function words (grammatical words) like articles ("the", "a"), conjunctions ("and", "but"), and prepositions ("in", "on") primarily serve syntactic purposes and maintain grammatical structure. Content words (open-class words) such as nouns, verbs, and adjectives carry semantic meaning and refer to specific concepts.

### How Humans Process Different Word Classes

Human readers show a clear preference for processing content words:

1. **Eye-Tracking Evidence**: Humans fixate on content words (nouns, verbs) significantly more than function words. Function words like "the" and "and" are frequently skipped during reading, while readers rest approximately 250 milliseconds on content words.

2. **Cognitive Load**: The reading eye fixates on most content words in a rapid series of stops and jumps (fixations and saccades), while taking approximately 7-9 letters to the right of fixation. Function words are often processed peripherally without dedicated fixation time.

3. **Grammatical Processing**: In human cognition, parsing relies on working memory to maintain grammatical structure, but the semantic content carried by content words is what drives comprehension and extends across longer text spans.

### How LLMs Process Different Word Classes

LLMs demonstrate fundamentally different processing patterns compared to humans:

1. **Uniform Treatment of Function Words**: Unlike humans who skip or quickly scan function words, LLMs treat function words more uniformly across categories. When tested for "concreteness ratings," humans assigned varying values to different function words (e.g., "in" and "more" perceived as more concrete than "of" or "because"), while LLMs consistently rated all function words as similarly low in concreteness, failing to capture nuanced differences.

2. **Attention Mechanism Distribution**: The self-attention mechanism in transformer models (like BERT) weights the importance of each token (word or subword) relative to others in the sequence. However, this mechanism may not align with human priorities—LLMs can theoretically allocate attention to any token, while humans prioritize content words.

3. **Semantic-Driven Processing**: Research shows that lexical-semantic content (primarily from content words) rather than syntactic structure (conveyed by function words) is the main contributor to how neural language models align with human brain activity. This suggests LLMs, like humans, prioritize semantic content, but the mechanism by which function words are incorporated differs significantly.

4. **Task-Dependent Importance**: Stop word removal studies show that the importance of function words varies by task. For syntax-dependent applications (NER, machine translation), keeping function words is critical. In sentiment analysis, function words like "not" in negation phrases ("not good") are essential for accurate meaning. LLMs struggle with tasks requiring structural preservation where function words are critical anchors.

### Key Divergence: Human vs LLM Handling of Function Words

The critical finding is that **function words show pronounced discrepancies between human and LLM representations**:

- Humans variably perceive function words (some as more concrete, others as abstract)
- LLMs consistently underrepresent the nuanced distinctions in function word meanings and treat them as uniformly similar
- In word embeddings and neural representations, function words may occupy less differentiated space compared to content words
- Content words show much stronger alignment between human psychological ratings and LLM representations

### Stop Words in NLP Systems

Traditional NLP approaches remove "stop words" (mainly function words) to reduce dimensionality (35-45% reduction in word count). However, this approach has proven counterproductive for modern LLMs and neural systems because:

1. Complete function word removal loses critical information in semantically sensitive tasks
2. Machine translation, text summarization, and sentiment analysis require function words for accurate meaning
3. Neural networks benefit from context provided by function words, especially for grammatical correctness
4. The presence of function words helps ensure grammaticality in next-token prediction within local sentence contexts

### Word Class Importance in Transformers and Neural Networks

Research on BERT and transformer models reveals:

1. **Content Words Drive Semantic Alignment**: The lexical-semantic content (predominantly from nouns, verbs, adjectives) is primarily responsible for ANN-to-brain similarity, not syntactic structure.

2. **Verbs Are Particularly Important**: Verbs are arguably the most important lexical category, as sentences require them to convey actions and states. In neural networks, verbs produce distinct synaptic activity patterns, particularly in prefrontal activation during grammatical and lexical processing.

3. **Token Importance Embedding**: Recent work shows that explicitly encoding word importance as a new embedding layer in transformers improves performance (GLUE benchmark improved from 75.8 to 76.8; SuperGLUE from 89.3 to 90.5), suggesting that models benefit from explicit recognition of differential word importance.

4. **Attention Mechanisms Are Universal**: All tokens receive attention weights in transformer models, but this doesn't mean attention is equally informative for all word classes. Function words may receive high attention for grammatical structure, while content words receive attention for semantic content.

### Morphosyntactic Features and LLM Limitations

LLMs show measurable limitations in handling grammatical categories:

1. **Grammatical Drift**: LLM-generated text differs from human text at the morphosyntactic level, with LLMs preferring parts of speech that display objectivity (symbols, numbers) while using substantially fewer adjectives.

2. **Subtle Feature Detection**: Features like African American English "Habitual Be" are difficult for LLMs to detect without explicit representation of underlying grammatical structure.

3. **Variable Similarity by Model Size**: Larger models show greater similarity to human patterns in linguistic structure, but even the largest models diverge from humans more substantially than different human texts diverge from each other.

---

## Research Sources (11+)

1. **Content Words, Function Words, and LLM Analysis of Dictionaries – Skywritings** (2023)
   - URL: https://generic.wordpress.soton.ac.uk/skywritings/2023/09/16/content-words-function-words-and-llm-analysis-of-dictionaries/
   - Contribution: Directly addresses LLM handling of function vs. content words, showing that LLMs consistently underrate function word concreteness compared to human variability in perception.

2. **NLP Series: Day 4 — Stopword Removal and Normalization | Medium** (Ebrahim Mousavi)
   - URL: https://medium.com/@ebimsv/nlp-series-day-4-stopword-removal-and-normalization-418e0ec0016b
   - Contribution: Discusses practical implications of removing function words in NLP, showing 35-45% dimensionality reduction but task-dependent effectiveness.

3. **Stop Words in NLP: Understanding Their Role in Text Processing | BotPenguin**
   - URL: https://botpenguin.com/glossary/stop-words
   - Contribution: Comprehensive overview of stop word handling in NLP systems, emphasizing context-dependent impact on model performance across different tasks.

4. **Chapter 3 Stop words | Supervised Machine Learning for Text Analysis in R**
   - URL: https://smltar.com/stopwords.html
   - Contribution: Provides evidence that stop word removal benefits are task-specific and can harm performance in semantic and syntactic tasks.

5. **Whose LLM is it Anyway? Linguistic Comparison and LLM Attribution for GPT-3.5, GPT-4 and Bard** (arxiv)
   - URL: https://arxiv.org/html/2402.14533v1
   - Contribution: Analyzes LLM usage of determiners, prepositions, and conjunctions, showing variation across models in their use of function word classes.

6. **How well do large language models mirror human cognition of word concepts?: A comparison of psychological ratings for early-acquired English words | Behavior Research Methods** (Springer Nature)
   - URL: https://link.springer.com/article/10.3758/s13428-025-02938-2
   - Contribution: Recent empirical research directly comparing human psychological ratings with LLM representations for different word types, particularly highlighting function word discrepancies.

7. **Eye Movements and Reading | Reading Rockets**
   - URL: https://www.readingrockets.org/topics/reading-and-brain/articles/eye-movements-and-reading
   - Contribution: Demonstrates human eye-tracking evidence that content words receive fixations while function words are frequently skipped, providing neurolinguistic baseline for human processing.

8. **Using Eye Movements to Evaluate the Cognitive Processes Involved in Text Comprehension | PMC**
   - URL: https://pmc.ncbi.nlm.nih.gov/articles/PMC4089416/
   - Contribution: Detailed analysis of eye-tracking methodology showing increased processing time associated with content words vs rapid scanning of function words.

9. **The processing of verbs and nouns in neural networks: insights from synthetic brain imaging | PubMed**
   - URL: https://pubmed.ncbi.nlm.nih.gov/15068924/
   - Contribution: Shows distinct neural processing patterns for different content word classes (verbs vs. nouns), with verbs producing prefrontal activation during grammatical processing.

10. **Lexical-Semantic Content, Not Syntactic Structure, Is the Main Contributor to ANN-Brain Similarity of fMRI Responses in the Language Network | MIT Press**
    - URL: https://direct.mit.edu/nol/article/5/1/7/116784/Lexical-Semantic-Content-Not-Syntactic-Structure
    - Contribution: Critical finding that semantic content (from content words) drives ANN-brain similarity more than syntactic structure (from function words), suggesting LLMs align with human processing through semantic rather than grammatical pathways.

11. **Do LLMs write like humans? Variation in grammatical and rhetorical styles | PNAS**
    - URL: https://www.pnas.org/doi/10.1073/pnas.2422455122
    - Contribution: Demonstrates morphosyntactic differences between human and LLM-generated text, particularly showing LLMs use fewer adjectives and fewer variations in function word deployment compared to human writing.

12. **Enhancing performance of transformer-based models in natural language understanding through word importance embedding | ScienceDirect**
    - URL: https://www.sciencedirect.com/science/article/abs/pii/S0950705124010384
    - Contribution: Shows that explicit word importance embeddings improve transformer performance (GLUE +1.0, SuperGLUE +1.2), suggesting transformers benefit from recognizing differential importance of word classes.

13. **Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns | arxiv**
    - URL: https://arxiv.org/html/2601.14112
    - Contribution: Details how attention mechanisms assign importance to tokens, providing technical foundation for understanding whether function vs. content words receive differential attention patterns.

---

## Conclusion

Function words are **not truly "droppable" for LLMs** in the way they might be for humans in reading tasks. While humans physiologically skip many function words during reading and rely heavily on content words for semantic comprehension, LLMs treat function words as integral to token sequence processing. However, LLMs **misunderstand function word semantics** compared to humans—they fail to capture the nuanced psychological distinctiveness humans perceive in different function words.

The evidence suggests that LLMs and humans rely on word classes differently:
- **Humans**: Prioritize content words through selective attention (eye fixations) while using function words primarily to maintain grammatical scaffolding
- **LLMs**: Allocate processing across all tokens via attention mechanisms, prioritizing semantic content (from content words) but treating function words as relatively undifferentiated and semantically impoverished

This represents a fundamental divergence in how word class droppability operates: humans can functionally skip many function words without comprehension loss, while LLMs require them for syntactic coherence, yet fail to represent them as psychologically distinct entities.
