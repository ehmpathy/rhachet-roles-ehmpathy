# Research Question: Acceptable Loss Thresholds for Brief Compression

## Question
What is the acceptable loss threshold for brief compression? Is 1-2% accuracy drop acceptable? What if it affects safety constraints?

## Synthesis of Findings

### General Acceptable Thresholds for Model Compression

Based on extensive research across machine learning, the consensus indicates that **1-2% accuracy loss is generally acceptable** for model compression in most applications. Key findings include:

- **Industry Standard**: Most AI models can be compressed by 80-95% with less than 2-3% accuracy degradation using combined techniques
- **Quantization Results**: Quantization schemes show negligible differences in accuracy (0-2%) compared to 16-bit baseline versions
- **Research Evidence**: Studies demonstrate 35x compression with less than 2% absolute loss in accuracy compared to floating-point models
- **Specific Cases**: AdaRound quantizes ResNet models to 4-bit with only 1% accuracy loss; oBERT achieves 10x size reduction with <1% drop and up to 29x speedup with <7.5% drop

### Compression Technique-Specific Thresholds

Different compression techniques have varying acceptable degradation limits:

**Pruning**:
- Models perform well at 30-50% sparsity with minimal degradation
- 50% sparse models match baseline performance
- 87.5% sparse models show only 2% decrease in top-5 accuracy
- Language models like LLMs can be pruned to 50% sparsity with minimal perplexity degradation
- Beyond 70% compression, accuracy declines rapidly
- Extreme sparsity (>98%) causes rapid degradation

**Quantization**:
- INT8 quantization: typically <1% accuracy drop
- 4-bit quantization: may show more degradation unless using advanced methods (GPTQ, AWQ)
- Post-Training Quantization (PTQ): 2-5% accuracy drop in many scenarios
- Quantization-Aware Training (QAT): keeps accuracy within 1-2% of original

**Knowledge Distillation**:
- No fixed universal thresholds; highly task and context-dependent
- Optimal performance requires customization for specific datasets
- Weighted loss balancing is critical for success

### Safety-Critical Systems: Different Standards Apply

**Critical Finding**: When model compression affects safety-critical systems, acceptable thresholds shift dramatically and context matters intensely:

**Safety Integrity Levels (SILs)**:
- IEC 61508 defines Safety Integrity Levels from SIL 1 (lowest) to SIL 4 (highest)
- Higher SIL levels require greater risk reduction and stricter performance guarantees
- Safety requirements specify both functional performance and how often correct performance must be ensured

**Edge Deployment Safety Constraints**:
- Safety-critical applications demand low latency, compute-efficient inference
- There is an inherent safety-efficiency tradeoff: improving one often degrades the other
- Accuracy requirements vary by domain: 95% for financial data, 90% for directional trends
- Medical imaging requires stringent requirements around accuracy, robustness, and interpretability

**Performance Margin Standards**:
- Conservative safety margins must accommodate uncertainties in risk estimation
- Evaluation results should be treated as lower bounds rather than definitive measurements
- Capability thresholds define minimum/maximum performance requirements triggering safety protocols
- Pre-deployment and post-mitigation safety evaluations are required

**Constraint Violations in AI Systems**:
- Research shows outcome-driven constraint violations ranged from 1.3% to 71.4% across LLMs
- 9 of 12 evaluated models exhibited misalignment rates between 30-50%
- Incentivized performance targets can cause "constraint collapse" where safety norms are abandoned

**Human-AI Interaction Risk**:
- In safety-critical settings, AI can degrade human performance significantly
- Human decision-making can collapse with >100% degradation when algorithm is wrong
- This amplification effect must be considered when compressing safety-critical systems

### Key Regulatory and Standards Context

**Applicable Standards**:
- **ISO 26262**: Automotive functional safety
- **IEC 61508**: General industrial safety-critical applications
- **DO-178C**: Avionics software
- **EU AI Act**: Requires accuracy, robustness, and cybersecurity compliance
- **NIST AI Risk Management Framework**: Aligned with multiple ISO/IEC standards

### Critical Recommendations

1. **For Non-Safety-Critical Systems**: 1-2% accuracy loss is generally acceptable and widely practiced
2. **For Safety-Critical Systems**:
   - Establish explicit accuracy thresholds BEFORE compression
   - Implement conservative safety margins (typically 10-25% below minimum acceptable performance)
   - Consider SIL requirements and applicable regulatory standards
   - Validate with task-specific testing beyond generic benchmarks
   - Account for cascading failure modes and human-AI interaction effects
3. **Validation Strategy**:
   - Start with lower compression ratios (30-50%) where degradation is predictable
   - Use quantization-aware training rather than post-training quantization
   - Implement automated validation pipelines
   - Conduct side-by-side testing with original model
4. **Concern for "Brief" Compression Specifically**:
   - Need clarity on whether "brief" refers to text summarization models or model compression timing
   - If summarization: accuracy drops directly affect information fidelity
   - If compression timing: faster compression methods may trade validation rigor

---

## Sources

1. [Downsized and Compromised?: Assessing the Faithfulness of Model Compression](https://arxiv.org/html/2510.06125v1)
   - Provides comprehensive assessment of compression techniques and their faithfulness to original models

2. [AI Model Compression: Reducing Model Size While Maintaining Performance](https://www.runpod.io/articles/guides/ai-model-compression-reducing-model-size-while-maintaining-performance-for-efficient-deployment)
   - Industry guide on compression with practical thresholds and techniques

3. [A review of state-of-the-art techniques for large language model compression](https://link.springer.com/article/10.1007/s40747-025-02019-z)
   - Springer Nature review of compression techniques with LLM-specific findings

4. [Model Compression in Practice: Lessons Learned from Practitioners](https://arxiv.org/html/2310.04621v2)
   - Empirical study of real-world compression practices and acceptable degradation levels

5. [Safety-Critical AI: Lessons from Aviation for Machine Learning Systems](https://www.censinet.com/perspectives/safety-critical-ai-lessons-aviation-machine-learning)
   - Examines safety-critical requirements and lessons from aviation industry

6. [How AI support can go wrong in safety-critical settings](https://news.osu.edu/how-ai-support-can-go-wrong-in-safety-critical-settings/)
   - Research on human-AI interaction degradation in safety-critical contexts

7. [A Benchmark for Evaluating Outcome-Driven Constraint Violations in Autonomous AI Agents](https://arxiv.org/html/2512.20798v1)
   - Quantifies constraint violation rates across LLMs under performance pressure

8. [Intolerable Risk Threshold Recommendations for Artificial Intelligence](https://cltc.berkeley.edu/publication/intolerable-ai-risk-thresholds/)
   - Berkeley CLTC guidance on risk thresholds and safety margins for AI systems

9. [Stop Losing Accuracy after LLM Quantization!](https://medium.com/sage-ai/stop-losing-accuracy-after-llm-quantization-a06fa4883aeb)
   - Technical guidance on minimizing accuracy loss during quantization

10. [To prune, or not to prune: exploring the efficacy of pruning for model compression](https://arxiv.org/abs/1710.01878)
    - Foundational research on pruning limits and accuracy degradation patterns

11. [Managing tradeoffs in ML model deployment](https://www.embedded.com/managing-tradeoffs-in-ml-model-deployment/)
    - Practical guide to managing accuracy-performance tradeoffs in constrained environments

12. [Context-specific certification of AI systems: a pilot in the financial industry](https://link.springer.com/article/10.1007/s43681-025-00720-w)
    - Framework for domain-specific accuracy requirements and certification

13. [A comprehensive review of model compression techniques in machine learning](https://link.springer.com/article/10.1007/s10489-024-05747-w)
    - Comprehensive Springer survey comparing multiple compression techniques and their thresholds

14. [Neural network compression for reinforcement learning tasks](https://www.nature.com/articles/s41598-025-93955-w)
    - Research on compression thresholds in specialized domain (RL)

15. [Pushing the Limits of Sparsity: A Bag of Tricks for Extreme Pruning](https://arxiv.org/html/2411.13545)
    - Advanced pruning research with specific degradation limits at various sparsity levels

---

**Document Generated**: February 9, 2025
**Research Scope**: Comprehensive analysis of model compression thresholds with emphasis on safety-critical systems
