# Comprehensive Kernel Catalog: Brief Minification Research

**Date**: 2026-02-09
**Source Files**: 35 probe research responses (q1-q35)
**Purpose**: Unified catalog of knowledge kernels for telegraphic semantic compression of LLM briefs

---

## Executive Summary

This catalog synthesizes knowledge kernels extracted from 35 research probes that investigated brief minification for LLM consumption. The kernels are classified into four types:

| Type | Definition | Count (est.) |
|------|---------|--------------|
| [FACT] | Empirically or logically verifiable knowledge | ~400 |
| [SUMP] | Assumptions not explicitly proven | ~180 |
| [KHUE] | Questions defined and available to explore | ~200 |
| [HYPO] | Hypotheses proposed but not yet tested | ~280 |

**Total estimated kernels**: ~1,060 across 35 research probes

---

## Domain Hierarchy (Treestruct Index)

```
compression/
├── theory/
│   ├── information-theory/          [q5, q7, q25]
│   │   ├── shannon-entropy
│   │   ├── compression-limits
│   │   └── redundancy-analysis
│   ├── linguistics/                  [q1, q2, q3, q4]
│   │   ├── semantic-units
│   │   ├── function-vs-content-words
│   │   ├── syntactic-structure
│   │   └── telegraphic-speech
│   └── formal-semantics/             [q1]
│       ├── predicate-argument-structure
│       ├── frame-semantics
│       └── discourse-representation
├── methods/
│   ├── token-level/                  [q9, q10, q11, q12]
│   │   ├── llmlingua
│   │   ├── llmlingua-2
│   │   └── extractive-compression
│   ├── semantic-level/               [q23, q24]
│   │   ├── semantic-hash
│   │   ├── embed-compression
│   │   └── custom-models
│   ├── telegraphic/                  [q4, q20]
│   │   ├── tsc-principles
│   │   └── stop-word-removal
│   └── symbolic/                     [q19]
│       └── structured-format-compression
├── evaluation/
│   ├── metrics/                      [q13, q14, q15, q16]
│   │   ├── semantic-preservation
│   │   ├── behavioral-equivalence
│   │   ├── constraint-compliance
│   │   └── llm-as-judge
│   ├── benchmarks/                   [q12, q35]
│   │   └── compression-benchmarks
│   └── test-frameworks/              [q35]
│       └── ab-test-frameworks
├── application/
│   ├── brief-zones/                  [q17, q18]
│   │   ├── zone-compression-tolerance
│   │   └── never-drop-tokens
│   ├── production/                   [q32, q33]
│   │   ├── documented-uses
│   │   └── system-prompts
│   ├── preprocess/                   [q22, q26]
│   │   ├── small-llm-preprocess
│   │   └── kv-cache-interaction
│   └── multi-language/               [q21]
│       └── jargon-compression
└── inversions/
    ├── failure-modes/                [q27, q29, q34]
    │   ├── compression-failures
    │   ├── ambiguity-harm
    │   └── behavioral-drift
    ├── verbosity-necessity/          [q25, q28]
    │   ├── redundancy-for-robustness
    │   └── when-more-is-better
    ├── adaptive/                     [q30]
    │   └── adaptive-compression
    └── train-bias/                   [q31]
        └── train-data-effects
```

---

## Domain Clusters

### 1. LINGUISTICS AND FORMAL SEMANTICS

**Sources**: q1, q2, q3, q4

**Core Facts**:
- Content words carry lexical-semantic content; function words encode syntactic structure
- Predicate-argument structure is foundational to semantic representation across formal theories
- Telegraphic speech emerges universally in child language acquisition (18-30 months)
- N400 ERP component is smaller for function words than content words of similar frequency
- Elementary predications in MRS are atomic semantic units that cannot be further decomposed

**Key Hypotheses**:
- Content words constitute MVSUs (Minimal Viable Semantic Units) for LLM comprehension
- Function words are semantically redundant when strong world knowledge enables reconstruction
- Predicate-argument structure with content-word realization constitutes the MVSU for LLMs

**Open Questions**:
- Do different downstream tasks require different MVSUs?
- Do MVSUs differ across languages with different morphological properties?

---

### 2. INFORMATION THEORY AND COMPRESSION LIMITS

**Sources**: q5, q6, q7, q25

**Core Facts**:
- Natural English has 74-75% redundancy (0.6-1.58 bits/character entropy)
- Shannon's source code theorem proves entropy is the absolute lower bound for lossless compression
- Semantic compression can approach 0.69-0.70 bits/character with state-of-the-art LLMs
- Phase transition at α* ≈ 0.4049 relative embedded dimension beyond which lossless semantic compression is impossible
- Lossy semantic compression can achieve 5-10x length reduction while it preserves semantic content

**Key Hypotheses**:
- Compressed briefs should target 1.4-1.6 bits/character entropy
- 50-60% size reduction is achievable while all functional information is preserved
- Redundancy serves essential communicative functions beyond information transmission

**Open Questions**:
- What is the optimal entropy target for mechanic briefs?
- How much redundancy is necessary for error resilience?

---

### 3. COMPRESSION METHODS AND TOOLS

**Sources**: q9, q10, q11, q12, q22, q23, q24

**Core Facts**:
- LLMLingua achieves up to 20x compression with minimal performance loss
- LLMLingua-2 achieves 3x-6x faster inference through BERT-level token classification
- Extractive compression outperforms abstractive (+7.89 F1 points) on multi-hop reason
- Hard-prompt approaches produce less hallucination than soft-prompts
- Small LLMs (GPT-2, DistilBERT) can serve as compression preprocessors

**Key Hypotheses**:
- Token-level compression preserves instruction constraints better than abstractive methods
- Symbolic compression achieves maximum behavioral equivalence at 60-80% token reduction
- Custom brief-specific models could achieve 40-50% additional compression improvement

**Open Questions**:
- What is the maximum compression ratio before behavioral equivalence degrades?
- Can compression algorithms automatically detect zone boundaries?

---

### 4. EVALUATION AND SEMANTIC PRESERVATION

**Sources**: q13, q14, q15, q16

**Core Facts**:
- Constraint compliance and semantic accuracy are statistically independent (r=0.193)
- Inter-rater reliability: κ=0.90 for constraint compliance vs κ=0.25 for semantic accuracy
- Constraint violations peak at medium compression (c=0.5) and decline at extremes
- RLHF ablation improves constraint compliance by 598% at c=0.5
- xRAG compression preserves only 28% of entities (dates: 22%, numbers: 26%)

**Key Hypotheses**:
- Constraint compliance is a more reliable metric than semantic similarity for brief compression
- Entity preservation requires explicit protection beyond general semantic similarity
- LLM-as-judge evaluation correlates with human judgment for compression quality

**Open Questions**:
- What metrics best capture instruction-follow fidelity?
- How should acceptable loss thresholds vary by brief zone?

---

### 5. BRIEF ZONES AND APPLICATION

**Sources**: q17, q18, q19, q20, q32, q33

**Core Facts**:
- Prompt components include: instruction, persona, context, exemplar, format, tone, constraint
- Identity/Role zones have LOW compression tolerance (0-10%)
- Constraints have VERY LOW compression tolerance (0-5%)
- Examples/Demonstrations have HIGH compression tolerance (50-95%)
- LLMLingua reduces response latency by 20-30% in production
- LongLLMLingua improves RAG performance by 21.4% with 4x compression

**Key Hypotheses**:
- Zone-aware compression with differentiated ratios outperforms uniform compression
- Optimal total compression for most briefs is 40-60%
- Structural sections prevent compression algorithms from harmful deletions

**Open Questions**:
- What compression ratios are safe for each zone type?
- How should compression differ for multi-turn vs single-shot prompts?

---

### 6. FAILURE MODES AND INVERSIONS

**Sources**: q27, q28, q29, q30, q31, q34

**Core Facts**:
- FDA prohibits lossy compression for digital mammograms
- Compression artifacts can be misinterpreted as genuine pathology in medical images
- Five systematic failure patterns: unknowable future requirements, artifact misinterpretation, generation loss, content-dependent failure, irreversible context elimination
- Over-compression causes format instruction violations, constraint boundary confusion, multi-step sequence breaks
- RLHF-trained behaviors are the dominant cause of constraint violations

**Key Hypotheses**:
- Compression is most valuable precisely where it is most dangerous (high-stakes applications)
- Compression failures manifest as systematic degradation rather than dramatic single-point catastrophes
- Ambiguity from compression creates compounded errors through multi-step reason chains

**Open Questions**:
- How can compression failures be detected before they cause downstream errors?
- What is the minimum redundancy threshold for error resilience?

---

### 7. STRATEGIC REDUNDANCY AND ADAPTIVE COMPRESSION

**Sources**: q25, q28, q30

**Core Facts**:
- Natural languages contain ~50% redundancy for error correction
- Hamming(7,4) codes add 75% overhead to enable single-bit error correction
- Triple Modular Redundancy accepts 200% overhead for near-certain reliability
- Redundant modifiers reduce parse errors by 37%

**Key Hypotheses**:
- Optimal compression sometimes requires expansion (strategic addition of information)
- Zone-specific redundancy levels should match content criticality
- Diverse restatement provides better robustness than mere repetition

**Open Questions**:
- When does clarification cost justify proactive redundancy?
- How should redundancy adapt to audience expertise and context quality?

---

## Cross-Domain Relations

### Relation 1: Linguistics → Compression Methods
- Linguistic theory (q1, q2) establishes that function words are predictable and reconstructible
- Compression methods (q9, q10) operationalize this by targeted function word removal
- Evaluation (q13) validates that constraint compliance survives function word removal

### Relation 2: Information Theory → Zone Tolerance
- Shannon entropy (q5) establishes redundancy rates for natural language
- Zone analysis (q17) maps redundancy to specific brief components
- Failure modes (q27) reveal what breaks when redundancy is insufficient

### Relation 3: Evaluation → Production Application
- Semantic preservation metrics (q13, q14) define success criteria
- Benchmarks (q12) validate compression method performance
- Production uses (q32) demonstrate real-world applicability

### Relation 4: Inversions → Compression Limits
- Failure modes (q27, q29) establish lower bounds on safe compression
- Redundancy research (q25, q28) defines when MORE text improves reliability
- Adaptive compression (q30) synthesizes into context-aware strategies

---

## Kernel Index by Probe

| Probe | Topic | Est. Kernels | Primary Domain |
|-------|-------|--------------|----------------|
| q1 | MVSU for LLM comprehension | 60 | linguistics/formal-semantics |
| q2 | Function vs content words | 45 | linguistics |
| q3 | Syntactic structure role | 35 | linguistics |
| q4 | Telegraphic/pidgin compression | 40 | linguistics |
| q5 | Shannon entropy instruction text | 58 | information-theory |
| q6 | Zipf's Law token info | 30 | information-theory |
| q7 | Theoretical compression limits | 25 | information-theory |
| q8 | LLMs as compressors | 28 | methods |
| q9 | LLMLingua ratios and cost | 35 | methods/token-level |
| q10 | LLMLingua vs TSC vs summarization | 34 | methods |
| q11 | LLMLingua-2 data distillation | 32 | methods/token-level |
| q12 | Prompt compression benchmarks | 40 | evaluation/benchmarks |
| q13 | Semantic preservation definition | 45 | evaluation/metrics |
| q14 | Eval for knowledge loss | 38 | evaluation/metrics |
| q15 | LLM-as-judge evaluation | 30 | evaluation/metrics |
| q16 | Acceptable loss thresholds | 35 | evaluation/metrics |
| q17 | Brief zones compression tolerance | 122 | application/brief-zones |
| q18 | Never-drop tokens | 40 | application/brief-zones |
| q19 | Structured format compression | 28 | methods/symbolic |
| q20 | Brief-specific stop words | 25 | methods/telegraphic |
| q21 | Multi-language/jargon compression | 30 | application/multi-language |
| q22 | Small LLM preprocess | 77 | application/preprocess |
| q23 | Semantic hash/embed | 35 | methods/semantic-level |
| q24 | Custom brief compression model | 30 | methods/semantic-level |
| q25 | Compression-expansion redundancy | 28 | inversions/verbosity-necessity |
| q26 | Prompt cache + KV-cache | 32 | application/preprocess |
| q27 | INVERSION: compression failures | 63 | inversions/failure-modes |
| q28 | INVERSION: verbosity necessity | 35 | inversions/verbosity-necessity |
| q29 | INVERSION: ambiguity harm | 30 | inversions/failure-modes |
| q30 | INVERSION: adaptive compression | 38 | inversions/adaptive |
| q31 | INVERSION: train data bias | 25 | inversions/train-bias |
| q32 | Production compression uses | 50 | application/production |
| q33 | TSC for system prompts | 35 | application/production |
| q34 | Compression side effects | 40 | inversions/failure-modes |
| q35 | A/B test frameworks | 30 | evaluation/test-frameworks |

---

## Top 10 Most Grounded Facts

1. **LLMLingua 20x compression**: Achieves up to 20x compression with minimal performance loss (q9, q10, q32)
2. **Natural language 75% redundancy**: English text exhibits 74-75% redundancy at 0.6-1.58 bits/char (q5)
3. **Constraint compliance κ=0.90**: Near-perfect inter-rater reliability for constraint compliance vs κ=0.25 for semantics (q13)
4. **Content vs function word neural separation**: Different ERP components (N400 vs P600) for word types (q2)
5. **Extractive outperforms abstractive**: +7.89 F1 points on multi-hop reason at equivalent compression (q10)
6. **Phase transition at α*≈0.4049**: Theoretical limit for lossless semantic compression (q7)
7. **RLHF causes constraint violations**: 598% improvement when RLHF signals removed (q13)
8. **Entity preservation only 28%**: xRAG preserves only 28% of entities despite 66% semantic similarity (q13)
9. **Zone compression tolerance varies**: Identity 0-10%, Constraints 0-5%, Examples 50-95% (q17)
10. **FDA prohibits lossy mammogram compression**: Regulatory recognition of compression risks (q27)

---

## Top 10 Critical Assumptions to Validate

1. **LLMs reconstruct function words from context**: Assumes world knowledge enables reliable reconstruction (q1, q4)
2. **Compression tolerance inversely correlates with priority**: Zone priority determines safe compression ratio (q17)
3. **Semantic similarity equals task equivalence**: High similarity scores imply behavioral equivalence (q13)
4. **Telegraphic compression preserves instructions**: TSC maintains instruction-follow fidelity (q4, q10)
5. **Content words are high-entropy**: Assumes content words carry most information (q5)
6. **Zone boundaries are cleanly separable**: Assumes prompt components don't interdepend (q17)
7. **Baseline comprehension rate is high**: Justifies reactive over proactive redundancy (q25)
8. **Current evaluation metrics capture failure modes**: Assumes standard metrics detect all degradation (q27)
9. **Model quality determines compression limits**: State-of-the-art LLMs approach theoretical bounds (q7)
10. **Domain-specific patterns generalize**: Assumes findings transfer across brief types (q21)

---

## Top 10 Open Research Questions

1. **Optimal compression ratio per zone**: What is the precise threshold before degradation begins? (q17)
2. **Behavioral equivalence measurement**: How to reliably measure instruction-follow fidelity? (q13, q15)
3. **Minimum redundancy for resilience**: What redundancy level prevents error cascades? (q25, q27)
4. **Cross-zone dependencies**: How do zone interactions affect optimal compression? (q17)
5. **Adaptive compression signals**: What metrics indicate need for increased redundancy? (q30)
6. **Entity preservation techniques**: How to protect dates, numbers, and named entities? (q13)
7. **Multi-turn compression strategies**: How should compression differ for conversations? (q17)
8. **Compression failure detection**: How to identify failures before downstream errors? (q27)
9. **Task-specific compression limits**: Do different tasks require different MVSUs? (q1)
10. **Train data bias effects**: How does compression affect RLHF-trained behaviors? (q31)

---

## Top 10 Testable Hypotheses

1. **H1**: Zone-aware compression with differentiated ratios outperforms uniform compression (q17)
2. **H2**: Constraint compliance degrades non-linearly with compression ratio, with inflection at 60-70% (q13, q16)
3. **H3**: Extractive compression preserves constraints better than abstractive at equivalent ratios (q10)
4. **H4**: Compressed briefs at 1.4-1.6 bits/char entropy maintain full behavioral equivalence (q5)
5. **H5**: Entity protection markers reduce date/number loss from 78% to <20% (q13)
6. **H6**: Diverse restatement of critical points reduces comprehension failure by 37% vs repetition (q25)
7. **H7**: Small LLM preprocess achieves 80% of full LLM compression quality at 10% cost (q22)
8. **H8**: Symbolic compression achieves maximum equivalence at 60-80% token reduction (q10)
9. **H9**: Compression at medium ratios (c=0.5) causes more constraint violations than high or low (q13)
10. **H10**: Custom brief-specific tokenization achieves 40% additional compression improvement (q24)

---

## Methodological Notes

### Kernelization Process
1. Each probe file was processed by a dedicated subagent
2. Kernels were classified via the four-type taxonomy ([FACT], [SUMP], [KHUE], [HYPO])
3. Each kernel includes claim, source citation, and domain assignment
4. Academic gerunds were replaced with past participles per style guidelines

### Domain Assignment
- Primary domain assigned based on core research question
- Secondary domains noted for cross-cut kernels
- Treestruct hierarchy enables hierarchical navigation

### Validation Requirements
- [FACT] kernels require empirical or logical verification
- [SUMP] kernels require explicit test before reliance
- [KHUE] kernels define research priorities
- [HYPO] kernels provide testable predictions

---

## Next Steps

Based on this kernelization, recommended next actions:

1. **Empirical validation**: Test top 10 hypotheses with controlled experiments
2. **Assumption audit**: Validate top 10 assumptions before system design
3. **Metric development**: Create behavioral equivalence measurement framework
4. **Zone taxonomy refinement**: Validate compression tolerance ranges empirically
5. **Failure mode catalog**: Document observed compression failures for pattern match

---

**Catalog completed**: 2026-02-09
**Total kernel files processed**: 35
**Estimated total kernels**: ~1,060
**Primary domains identified**: 7 major clusters
**Cross-domain relations mapped**: 4 primary relation chains
