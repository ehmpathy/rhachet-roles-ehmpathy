# ğŸ§© .brief.demo: `multi-head self-attention on ambiguous words (value vectors evolve)`

## .what
this demo shows how two identical tokens â€” **â€œbankâ€** â€” begin with the same embedding but evolve into **different value vectors** after attention layers, depending on context. multi-head attention disambiguates their meaning dynamically.

---

## ğŸ¯ purpose
- demonstrate that identical word embeddings diverge into context-specific meanings
- show how q, k, v vectors are derived from hidden states
- illustrate how attention causes â€œbankâ€ (financial vs river) to separate

---

## âš™ï¸ demo setup

sentence:
> â€œthe **bank** raised interest rates, and she sat by the **bank** of the river.â€

toy hidden size = **4**, with **2 heads.**

---

### ğŸ”¹ step 1 â€” input embedding (same for both â€œbankâ€)

both tokens start with the **same embedding lookup** from the word embedding matrix:

- embedding(**bank**) = `[0.5, 0.7, 0.2, 0.1]`

this is identical for both occurrences, because embeddings are tied to vocabulary entries, not context.

---

### ğŸ”¹ step 2 â€” hidden states diverge

after one transformer block, the hidden state of each â€œbankâ€ diverges due to attending to different neighbors:

- hidden(**bank_financial**) = `[0.8, 0.2, 0.6, 0.1]`
- hidden(**bank_river**)     = `[0.1, 0.9, 0.2, 0.7]`

---

### ğŸ”¹ step 3 â€” compute q, k, v from hidden states

each hidden state is projected by learned matrices \( W_q, W_k, W_v \).

for simplicity, show only **value (v)** vectors here:

- v(**bank_financial**) = `[0.6, 0.5, 0.7, 0.2]`
- v(**bank_river**)     = `[0.2, 0.8, 0.3, 0.6]`

note: originally both banks had the **same v** if taken right after embedding, but after context mixing, they diverge.

---

### ğŸ”¹ step 4 â€” multi-head specialization

- **head 1 (financial context):**
  â€œbankâ€ attends to â€œinterest ratesâ€ â†’ reinforces v(**bank_financial**).

- **head 2 (geographic context):**
  â€œbankâ€ attends to â€œriverâ€ â†’ reinforces v(**bank_river**).

---

## ğŸ§© combined effect

- initially, both â€œbankâ€ tokens share the same vector (embedding).
- after attention, their hidden states â€” and thus their q/k/v vectors â€” diverge.
- multi-head attention ensures each occurrence is contextualized differently.

---

## ğŸ“Š insight
- **embeddings** are static (same for same word).
- **hidden states** are dynamic (different for each occurrence).
- **q, k, v** are projections of hidden states, so they also differ per occurrence.
- result: llms resolve word sense disambiguation in context by letting identical tokens evolve into different representations.

in short: **same word, same start â€” different meaning, different vectors.**
