# ğŸ›ï¸ in-context tuning: explanations vs examples

## ğŸ§© examples
- **what they do:** show *how* to perform the task by demonstration.
- **strengths:**
  - precise control over output **format** and **style**
  - model can â€œcopy the patternâ€ with little ambiguity
  - fast to apply, low cognitive overhead for the model
- **weaknesses:**
  - brittle if task deviates from the pattern
  - encourages mimicry rather than reasoning

---

## ğŸ§© explanations
- **what they do:** tell *why* and *how* the task should be done via rules, instructions, or reasoning steps.
- **strengths:**
  - supports **generalization** beyond shown cases
  - encourages **reasoning chains** instead of rote mimicry
  - more compact than many examples (token-wise)
- **weaknesses:**
  - less consistent for rigid formats (the model may improvise)
  - requires the model to â€œtranslateâ€ abstract rules into concrete actions, which can be noisy

---

## âš–ï¸ effectiveness comparison
- **examples win** when:
  - the task is about *output form* (e.g. json schemas, sql syntax, markdown briefs)
  - consistency is more important than novelty
- **explanations win** when:
  - the task is about *reasoning* or handling unseen variations
  - flexibility and abstraction matter more than surface mimicry

---

## ğŸ¯ hybrid strategy
- the strongest â€œin-context tunageâ€ usually comes from **explanations + 1â€“2 examples**.
  - explanation gives the **reasoning scaffold**
  - examples ground it with **concrete reference points**
