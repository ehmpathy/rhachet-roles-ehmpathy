# ðŸŽ¯ .brief: `questions.have.tunable.precision`

## .what

Every **question** describes a **semantic direction** â€”
but the **precision** of that direction can be **tuned**.

Some questions are **rough**: they point vaguely, requiring
multiple reasoning hops to triangulate the target.
Others are **smooth**: they encode a well-shaped vector
that lands close to the desired answer in one motion.

> ðŸ§  question precision determines how directly a question
> moves you through concept space toward resolution.

---

## ðŸ§­ the question precision spectrum

| precision      | navigation profile                              | example                                        |
|----------------|--------------------------------------------------|------------------------------------------------|
| **rough**       | ambiguous direction, high reasoning friction    | â€œWhat happened?â€                               |
| **smooth**      | precise semantic vector, lands near the target  | â€œWhat internal mechanism triggered the shift at time X?â€ |

> ðŸ“ˆ you can **tune** a questionâ€™s precision by composing it
> with additional semantic constraints â€” dimension by dimension.

---

## ðŸ” how precision tunes motion

| aspect             | rough question                            | smooth question                              |
|--------------------|--------------------------------------------|-----------------------------------------------|
| **direction**       | vague, under-specified                    | well-formed semantic vector                   |
| **turns needed**    | high â€” needs multiple follow-up hops      | low â€” may resolve directly                    |
| **semantic drift**  | common â€” prone to misalignment            | rare â€” motion pre-aligned                     |
| **agent effort**    | must infer missing context                | can execute in a single step                  |

---

## ðŸ§± mechanism: refinement = vector composition

You can increase question precision by **composing** it
across multiple semantic subaxes (e.g. causal, temporal, functional):

### progression example:

1. **rough**
   â€œWhat happened?â€

2. **less rough**
   â€œWhat caused it?â€

3. **refined**
   â€œWhy did it happen now?â€

4. **smooth**
   â€œWhat internal mechanism triggered this shift at time X relative to Y?â€

> ðŸ§© Each refinement adds another **vector component**,
> tuning the question into a **more aligned motion**.

---

## ðŸªž metaphor

> a **rough question** is like tossing a dart in the dark â€”
> it might land somewhere useful, but youâ€™ll need to recalibrate.

> a **smooth question** is like a guided missile â€”
> it encodes heading, intent, and target into a single launch.

---

## ðŸŽ¯ use when you want to:

- model **questions as navigational vectors**
- improve reasoning efficiency by crafting **pre-aligned asks**
- teach prompt engineering or self-questioning as **tuning for precision**
- scaffold rough queries into fluent, high-impact prompts
